{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2821a5c9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\n",
    "    \"data/WF 3 F1-R12 - Great Britain.xlsx\",\n",
    "    sheet_name=\"Worksheet\",  # Specify the tab name\n",
    "    header=5 # Specify the 4th row as the header\n",
    ")\n",
    "\n",
    "# print(df.head())\n",
    "# print(df.columns)\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a50d036-52b9-4b94-8fae-188c3c6a0b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DataFrame loaded successfully from Excel.\n",
      "\n",
      "--- Program Classification Results Sample ---\n",
      "| Program Title                                         | Start Datetime      | Duration_td     | Classified Type          |\n",
      "|:------------------------------------------------------|:--------------------|:----------------|:-------------------------|\n",
      "| El Show de la F1        -O El Show de la F1        -O | 2025-07-03 22:00:00 | 0 days 01:00:00 | Highlights/Short Segment |\n",
      "| FORMULA 1 PRACTICAS(R)                                | 2025-07-04 16:00:03 | 0 days 01:09:26 | Other Long Segment       |\n",
      "| FORMULA 1 PRACTICAS(R2)                               | 2025-07-04 17:09:29 | 0 days 01:10:50 | Other Long Segment       |\n",
      "| FORMULA 1 PRACTICAS(R3)                               | 2025-07-04 21:01:16 | 0 days 01:10:09 | Other Long Segment       |\n",
      "| FORMULA 1 PRACTICAS(R4)                               | 2025-07-04 22:11:25 | 0 days 01:09:35 | Other Long Segment       |\n",
      "| FORMULA 1 PRACTICAS(R)                                | 2025-07-05 15:01:27 | 0 days 01:10:43 | Other Long Segment       |\n",
      "| FORMULA UNO CLASIFICA(R)                              | 2025-07-05 16:12:10 | 0 days 01:18:00 | Other Long Segment       |\n",
      "| FORMULA 1 PRACTICAS(R2)                               | 2025-07-05 19:30:00 | 0 days 01:10:39 | Other Long Segment       |\n",
      "| FORMULA UNO CLASIFICA(R2)                             | 2025-07-05 20:40:39 | 0 days 01:19:27 | Other Long Segment       |\n",
      "| FORMULA 1 PRACTICAS(R)                                | 2025-07-06 07:30:09 | 0 days 01:09:58 | Other Long Segment       |\n",
      "\n",
      "--- Summary of Classified Types ---\n",
      "| Classified Type                 |   count |\n",
      "|:--------------------------------|--------:|\n",
      "| Highlights/Short Segment        |    1559 |\n",
      "| Other Long Segment              |    1323 |\n",
      "| Repeat Broadcast                |      65 |\n",
      "| Unknown/No Duration             |      35 |\n",
      "| Formula 1 Highlights            |       4 |\n",
      "| LIVE (Race/Quali)               |       4 |\n",
      "| Formula 1 Qualifying Highlights |       4 |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from datetime import datetime, time\n",
    "\n",
    "# --- 0. Data Loading ---\n",
    "# NOTE: This line requires your file to be present at the specified path.\n",
    "try:\n",
    "    df = pd.read_excel(\n",
    "        \"data/WF 3 F1-R12 - Great Britain.xlsx\",\n",
    "        sheet_name=\"Worksheet\",\n",
    "        header=5 \n",
    "    )\n",
    "    print(\"âœ… DataFrame loaded successfully from Excel.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ ERROR: File not found. Please ensure 'data/WF 3 F1-R12 - Great Britain.xlsx' is correct.\")\n",
    "    # Exit or create an empty DataFrame to allow the code structure to run\n",
    "    df = pd.DataFrame() \n",
    "    \n",
    "if df.empty:\n",
    "    print(\"Cannot proceed with an empty DataFrame.\")\n",
    "    exit()\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 1. Define Live Schedule and Setup ðŸ—“ï¸\n",
    "\n",
    "# Schedule provided previously:\n",
    "live_schedule = [\n",
    "    ('Practice 1', '4-Jul-2025', '11:30:00'),\n",
    "    ('Practice 2', '4-Jul-2025', '15:00:00'),\n",
    "    ('Practice 3', '5-Jul-2025', '10:30:00'),\n",
    "    ('Qualifying', '5-Jul-2025', '14:00:00'),\n",
    "    ('GRAND PRIX', '6-Jul-2025', '14:00:00')\n",
    "]\n",
    "\n",
    "live_events = {}\n",
    "for title, date_str, time_str in live_schedule:\n",
    "    live_dt = pd.to_datetime(f\"{date_str} {time_str}\", format='%d-%b-%Y %H:%M:%S')\n",
    "    # Use the main event title part as the key\n",
    "    simplified_title = title.split('(')[0].strip()\n",
    "    live_events[simplified_title] = live_dt\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 2. Robust Date/Time Combination (Fix for original ValueError)\n",
    "\n",
    "def extract_time_string(time_value):\n",
    "    \"\"\"Safely extracts the time component as an HH:MM:SS string.\"\"\"\n",
    "    if pd.isna(time_value):\n",
    "        return '00:00:00'\n",
    "    if isinstance(time_value, time):\n",
    "        return time_value.strftime('%H:%M:%S')\n",
    "    if isinstance(time_value, datetime):\n",
    "        return time_value.time().strftime('%H:%M:%S')\n",
    "    try:\n",
    "        return pd.to_datetime(str(time_value)).time().strftime('%H:%M:%S')\n",
    "    except:\n",
    "        return '00:00:00'\n",
    "\n",
    "# Ensure 'Date' column is correct datetime type\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "# A. Clean the 'Start' column\n",
    "df['Clean_Time_Str'] = df['Start'].apply(extract_time_string)\n",
    "\n",
    "# B. Correctly combine Date and Time strings, then convert to datetime\n",
    "df['Start Datetime'] = df['Date'].dt.strftime('%Y-%m-%d') + ' ' + df['Clean_Time_Str']\n",
    "df['Start Datetime'] = pd.to_datetime(df['Start Datetime'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 3. Duration and End Time Calculation â³\n",
    "\n",
    "def parse_duration(duration_str):\n",
    "    \"\"\"Safely converts duration string to Timedelta.\"\"\"\n",
    "    if pd.isna(duration_str) or str(duration_str).strip() == '':\n",
    "        return pd.Timedelta(seconds=0)\n",
    "    try:\n",
    "        parts = str(duration_str).split(':')\n",
    "        if len(parts) == 3:\n",
    "             h, m, s = map(int, parts)\n",
    "             return pd.Timedelta(hours=h, minutes=m, seconds=s)\n",
    "        if isinstance(duration_str, pd.Timedelta):\n",
    "            return duration_str\n",
    "    except:\n",
    "        pass\n",
    "    return pd.Timedelta(seconds=0)\n",
    "\n",
    "df['Duration_td'] = df['Duration'].apply(parse_duration)\n",
    "df['End Datetime'] = df['Start Datetime'] + df['Duration_td']\n",
    "df = df.replace({pd.NaT: np.nan}) \n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 4. Programmatic Classification (Categorization Logic) ðŸ·ï¸\n",
    "\n",
    "# Define time offsets using pd.Timedelta\n",
    "MIN_LIVE_DURATION = pd.Timedelta(minutes=90) \n",
    "MIN_PRACTICE_DURATION = pd.Timedelta(minutes=60)\n",
    "MAX_HIGHLIGHTS_DURATION = pd.Timedelta(minutes=60)\n",
    "LIVE_WINDOW = pd.Timedelta(minutes=30) \n",
    "GRACE_PERIOD = pd.Timedelta(hours=2) \n",
    "\n",
    "def classify_program(row):\n",
    "    # Ensure all required columns exist before proceeding\n",
    "    if 'Program Title' not in df.columns:\n",
    "        return 'Column Missing'\n",
    "        \n",
    "    title = str(row['Program Title']).strip().split('(')[0].strip()\n",
    "    start_dt = row['Start Datetime']\n",
    "    duration = row['Duration_td']\n",
    "\n",
    "    if pd.isna(start_dt) or pd.isna(duration) or duration == pd.Timedelta(seconds=0):\n",
    "        return 'Unknown/No Duration'\n",
    "        \n",
    "    live_dt = None\n",
    "    for event_title, dt in live_events.items():\n",
    "        if event_title in title:\n",
    "            live_dt = dt\n",
    "            break\n",
    "            \n",
    "    # 1. LIVE Classification\n",
    "    if live_dt is not None:\n",
    "        if (start_dt >= live_dt - LIVE_WINDOW) and (start_dt <= live_dt + GRACE_PERIOD):\n",
    "            if ('GRAND PRIX' in title or 'Qualifying' in title) and duration >= MIN_LIVE_DURATION:\n",
    "                return 'LIVE (Race/Quali)'\n",
    "            elif 'Practice' in title and duration >= MIN_PRACTICE_DURATION:\n",
    "                return 'LIVE (Practice)'\n",
    "\n",
    "    # 2. HIGHLIGHTS / SHORT SEGMENT Classification\n",
    "    if duration <= MAX_HIGHLIGHTS_DURATION:\n",
    "        if 'Highlights' in title or 'Review' in title or 'News' in title or 'Magazine' in title:\n",
    "             return title\n",
    "        return 'Highlights/Short Segment'\n",
    "\n",
    "    # 3. REPEAT Classification\n",
    "    if live_dt is not None:\n",
    "        if (start_dt > live_dt + GRACE_PERIOD) and (duration >= MIN_PRACTICE_DURATION):\n",
    "            return 'Repeat Broadcast'\n",
    "                \n",
    "    return 'Other Long Segment'\n",
    "\n",
    "df['Classified Type'] = df.apply(classify_program, axis=1)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 5. Summary Output\n",
    "\n",
    "print(\"\\n--- Program Classification Results Sample ---\")\n",
    "# Display the relevant columns\n",
    "print(df[['Program Title', 'Start Datetime', 'Duration_td', 'Classified Type']].head(10).to_markdown(index=False))\n",
    "\n",
    "print(\"\\n--- Summary of Classified Types ---\")\n",
    "print(df['Classified Type'].value_counts().to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "146b7980-5591-4a05-802c-88a529b1e5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DataFrame loaded successfully from Excel.\n",
      "âœ… Classification complete using Title-Agnostic, UTC-Based comparison logic.\n",
      "\n",
      "==================================================\n",
      "ðŸ“Š Program Type Summary (Global)\n",
      "==================================================\n",
      "| Classified Type                 |   Count |\n",
      "|:--------------------------------|--------:|\n",
      "| Highlights/Short Segment        |    1442 |\n",
      "| Repeat Broadcast                |     706 |\n",
      "| LIVE (Race/Quali)               |     379 |\n",
      "| LIVE (Practice/Session)         |     265 |\n",
      "| Other Long Segment              |     159 |\n",
      "| Unknown/No Duration             |      35 |\n",
      "| Formula 1 Highlights            |       4 |\n",
      "| Formula 1 Qualifying Highlights |       4 |\n",
      "\n",
      "==================================================\n",
      "ðŸŒ Market-Wise Channel-Wise Summary (Top 10)\n",
      "==================================================\n",
      "| Market    |   Channel ID |   Formula 1 Highlights |   Formula 1 Qualifying Highlights |   Highlights/Short Segment |   LIVE (Practice/Session) |   LIVE (Race/Quali) |   Other Long Segment |   Repeat Broadcast |\n",
      "|:----------|-------------:|-----------------------:|----------------------------------:|---------------------------:|--------------------------:|--------------------:|---------------------:|-------------------:|\n",
      "| Argentina |        50898 |                      0 |                                 0 |                          0 |                         0 |                   5 |                    0 |                  0 |\n",
      "| Argentina |         6275 |                      0 |                                 0 |                          2 |                         0 |                   0 |                    0 |                  0 |\n",
      "| Argentina |         4441 |                      0 |                                 0 |                          0 |                         1 |                   6 |                    0 |                  5 |\n",
      "| Argentina |         2732 |                      0 |                                 0 |                          0 |                         4 |                   0 |                    0 |                  9 |\n",
      "| Argentina |         1210 |                      0 |                                 0 |                          1 |                         0 |                   0 |                    0 |                  0 |\n",
      "| Armenia   |        41855 |                      0 |                                 0 |                          0 |                         0 |                   0 |                    1 |                  1 |\n",
      "| Australia |        25087 |                      0 |                                 0 |                          0 |                         0 |                   5 |                    0 |                  0 |\n",
      "| Australia |         7962 |                      0 |                                 0 |                          1 |                         0 |                   0 |                    0 |                  1 |\n",
      "| Australia |         6095 |                      0 |                                 0 |                         27 |                         3 |                   4 |                    0 |                 17 |\n",
      "| Australia |         6096 |                      0 |                                 0 |                          7 |                         0 |                   0 |                    0 |                  1 |\n",
      "\n",
      "==================================================\n",
      "ðŸ•’ Total Duration Summary (Live vs. Repeat)\n",
      "==================================================\n",
      "| Classified Type                 |   Total Duration (Hours) |\n",
      "|:--------------------------------|-------------------------:|\n",
      "| Formula 1 Highlights            |                     2.35 |\n",
      "| Formula 1 Qualifying Highlights |                     0.85 |\n",
      "| Highlights/Short Segment        |                   703.64 |\n",
      "| LIVE (Practice/Session)         |                   317.73 |\n",
      "| LIVE (Race/Quali)               |                   782.74 |\n",
      "| Other Long Segment              |                   286.71 |\n",
      "| Repeat Broadcast                |                  1214.32 |\n",
      "| Unknown/No Duration             |                     0    |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from datetime import datetime, time\n",
    "\n",
    "# --- 0. Data Loading ---\n",
    "# NOTE: This section relies on your successful loading of the Excel file.\n",
    "try:\n",
    "    df = pd.read_excel(\n",
    "        \"data/WF 3 F1-R12 - Great Britain.xlsx\",\n",
    "        sheet_name=\"Worksheet\",\n",
    "        header=5 \n",
    "    )\n",
    "    print(\"âœ… DataFrame loaded successfully from Excel.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ ERROR: File not found. Using dummy structure for logic demonstration.\")\n",
    "    # Create a dummy DataFrame if the file isn't found, ensuring column structure matches\n",
    "    df = pd.DataFrame({\n",
    "        'Program Title': ['F1 Preview', 'Practice 1 Live', 'P3 - Race Day', 'Quali Live', 'Quali Delayed', 'Race Live', 'Race Replay', 'Highlights'],\n",
    "        'Date (UTC/GMT)': pd.to_datetime(['2025-07-04', '2025-07-04', '2025-07-05', '2025-07-05', '2025-07-05', '2025-07-06', '2025-07-06', '2025-07-06']),\n",
    "        'Start (UTC)': [time(11, 0, 0), time(11, 30, 0), time(10, 30, 0), time(14, 0, 0), time(20, 0, 0), time(14, 0, 0), time(20, 0, 0), time(10, 0, 0)],\n",
    "        'Duration': ['00:30:00', '01:30:00', '01:30:00', '02:00:00', '02:00:00', '02:00:00', '02:00:00', '00:30:00'],\n",
    "        'Market': ['GB', 'FR', 'DE', 'GB', 'FR', 'DE', 'GB', 'FR'],\n",
    "        'Channel ID': [101.0, 102.0, 101.0, 101.0, 102.0, 101.0, 102.0, 101.0]\n",
    "    })\n",
    "    \n",
    "if df.empty:\n",
    "    print(\"Cannot proceed with an empty DataFrame.\")\n",
    "    exit()\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 1. Define Live Schedule and Setup ðŸ—“ï¸\n",
    "\n",
    "# Live schedule (defined in UTC)\n",
    "live_schedule = [\n",
    "    ('Practice 1', '4-Jul-2025', '11:30:00'),\n",
    "    ('Practice 2', '4-Jul-2025', '15:00:00'),\n",
    "    ('Practice 3', '5-Jul-2025', '10:30:00'),\n",
    "    ('Qualifying', '5-Jul-2025', '14:00:00'),\n",
    "    ('GRAND PRIX', '6-Jul-2025', '14:00:00')\n",
    "]\n",
    "\n",
    "live_events_dt = [pd.to_datetime(f\"{date} {time}\", format='%d-%b-%Y %H:%M:%S') for title, date, time in live_schedule]\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 2. Data Preparation (UTC & Duration) ðŸ› ï¸\n",
    "\n",
    "def extract_time_string(time_value):\n",
    "    \"\"\"Safely extracts the time component as an HH:MM:SS string.\"\"\"\n",
    "    if pd.isna(time_value): return '00:00:00'\n",
    "    if isinstance(time_value, time): return time_value.strftime('%H:%M:%S')\n",
    "    if isinstance(time_value, datetime): return time_value.time().strftime('%H:%M:%S')\n",
    "    try:\n",
    "        return pd.to_datetime(str(time_value)).time().strftime('%H:%M:%S')\n",
    "    except:\n",
    "        return '00:00:00'\n",
    "\n",
    "def parse_duration(duration_str):\n",
    "    \"\"\"Safely converts duration string to Timedelta.\"\"\"\n",
    "    if pd.isna(duration_str) or str(duration_str).strip() == '': return pd.Timedelta(seconds=0)\n",
    "    try:\n",
    "        parts = str(duration_str).split(':')\n",
    "        if len(parts) == 3:\n",
    "             h, m, s = map(int, parts)\n",
    "             return pd.Timedelta(hours=h, minutes=m, seconds=s)\n",
    "        if isinstance(duration_str, pd.Timedelta): return duration_str\n",
    "    except:\n",
    "        pass\n",
    "    return pd.Timedelta(seconds=0)\n",
    "\n",
    "# Create the definitive UTC Start Datetime column\n",
    "df['Date (UTC/GMT)'] = pd.to_datetime(df['Date (UTC/GMT)'], errors='coerce')\n",
    "df['Clean_Time_UTC_Str'] = df['Start (UTC)'].apply(extract_time_string)\n",
    "df['Start Datetime UTC'] = df['Date (UTC/GMT)'].dt.strftime('%Y-%m-%d') + ' ' + df['Clean_Time_UTC_Str']\n",
    "df['Start Datetime UTC'] = pd.to_datetime(df['Start Datetime UTC'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "\n",
    "# Calculate Duration_td\n",
    "df['Duration_td'] = df['Duration'].apply(parse_duration)\n",
    "df = df.replace({pd.NaT: np.nan}) \n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 3. Revised Programmatic Classification (Title-Agnostic) ðŸ·ï¸\n",
    "\n",
    "# Define time offsets\n",
    "MIN_LIVE_RACE_QUALI_DURATION = pd.Timedelta(minutes=90) \n",
    "MIN_LIVE_PRACTICE_DURATION = pd.Timedelta(minutes=60)\n",
    "MAX_HIGHLIGHTS_DURATION = pd.Timedelta(minutes=60)\n",
    "\n",
    "# WIDEST LIVE WINDOW: \n",
    "# Check from 1 hour before the *earliest* scheduled UTC event start\n",
    "# up to 6 hours after the *latest* scheduled UTC event start.\n",
    "LIVE_WINDOW_BEFORE = pd.Timedelta(hours=1) \n",
    "# Events can run up to 3 hours. 6 hours covers most time zone shifts and tape delays (e.g., 20 min).\n",
    "LIVE_THRESHOLD_AFTER = pd.Timedelta(hours=6) \n",
    "# Threshold for definite Repeats (must start at least 12 hours later than the official event time)\n",
    "REPEAT_THRESHOLD_AFTER = pd.Timedelta(hours=12)\n",
    "\n",
    "\n",
    "def classify_program_title_agnostic(row):\n",
    "    start_dt_utc = row['Start Datetime UTC']\n",
    "    duration = row['Duration_td']\n",
    "    title = str(row['Program Title']).strip().split('(')[0].strip() # Use for the specific highlight names\n",
    "\n",
    "    if pd.isna(start_dt_utc) or pd.isna(duration) or duration == pd.Timedelta(seconds=0):\n",
    "        return 'Unknown/No Duration'\n",
    "    \n",
    "    # --- 1. LIVE Classification (Time Proximity + Duration ONLY) ---\n",
    "    \n",
    "    is_live = False\n",
    "    \n",
    "    # Check if the program's UTC start time is near ANY of the official live events\n",
    "    for live_dt in live_events_dt:\n",
    "        if (start_dt_utc >= live_dt - LIVE_WINDOW_BEFORE) and \\\n",
    "           (start_dt_utc <= live_dt + LIVE_THRESHOLD_AFTER):\n",
    "            \n",
    "            # If duration is long enough, classify as LIVE. Since we can't use title, \n",
    "            # we classify based on the minimum required duration for a main session.\n",
    "            if duration >= MIN_LIVE_PRACTICE_DURATION:\n",
    "                # We can't distinguish Race/Quali/Practice without the title, so we use a general LIVE category\n",
    "                # If duration is very long, it's likely the Race/Quali\n",
    "                if duration >= MIN_LIVE_RACE_QUALI_DURATION:\n",
    "                     return 'LIVE (Race/Quali)'\n",
    "                else:\n",
    "                    return 'LIVE (Practice/Session)'\n",
    "    \n",
    "    # --- 2. REPEAT Classification (Starts Much Later + Long Duration) ---\n",
    "    \n",
    "    # Check if the program starts significantly later than ANY live event\n",
    "    for live_dt in live_events_dt:\n",
    "        if (start_dt_utc > live_dt + REPEAT_THRESHOLD_AFTER) and \\\n",
    "           (duration >= MIN_LIVE_PRACTICE_DURATION):\n",
    "            # If it's a long segment starting hours later, it's a Repeat\n",
    "            return 'Repeat Broadcast'\n",
    "\n",
    "    # --- 3. HIGHLIGHTS / SHORT SEGMENT Classification (Duration < 60 min) ---\n",
    "    if duration <= MAX_HIGHLIGHTS_DURATION:\n",
    "        # Keep specific highlight titles if they exist, otherwise use generic label\n",
    "        if 'Highlights' in title or 'Review' in title or 'News' in title:\n",
    "             return title\n",
    "        return 'Highlights/Short Segment'\n",
    "                \n",
    "    # If it didn't fit any of the strict time/duration windows, but is long\n",
    "    return 'Other Long Segment'\n",
    "\n",
    "df['Classified Type'] = df.apply(classify_program_title_agnostic, axis=1)\n",
    "\n",
    "print(\"âœ… Classification complete using Title-Agnostic, UTC-Based comparison logic.\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 4. Market-Wise, Channel-Wise Summary ðŸ“Š\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸ“Š Program Type Summary (Global)\")\n",
    "print(\"=\"*50)\n",
    "global_summary = df['Classified Type'].value_counts().to_frame().reset_index()\n",
    "global_summary.columns = ['Classified Type', 'Count']\n",
    "print(global_summary.to_markdown(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸŒ Market-Wise Channel-Wise Summary (Top 10)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Group by Market, Channel ID, and Classified Type\n",
    "market_channel_summary = df.groupby(['Market', 'Channel ID', 'Classified Type']).size().reset_index(name='Count')\n",
    "\n",
    "# Pivot for better readability: Markets as rows, Classified Types as columns\n",
    "market_channel_pivot = market_channel_summary.pivot_table(\n",
    "    index=['Market', 'Channel ID'],\n",
    "    columns='Classified Type',\n",
    "    values='Count',\n",
    "    fill_value=0\n",
    ").astype(int).reset_index()\n",
    "\n",
    "# Calculate total programs per Market/Channel for sorting\n",
    "market_channel_pivot['Total Programs'] = market_channel_pivot.sum(axis=1, numeric_only=True)\n",
    "market_channel_pivot = market_channel_pivot.sort_values(\n",
    "    by=['Market', 'Total Programs'], \n",
    "    ascending=[True, False]\n",
    ").drop(columns=['Total Programs'])\n",
    "\n",
    "\n",
    "# Display the resulting table\n",
    "print(market_channel_pivot.head(10).to_markdown(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸ•’ Total Duration Summary (Live vs. Repeat)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Calculate total duration for key types\n",
    "duration_summary = df.groupby('Classified Type')['Duration_td'].sum().dt.total_seconds() / 3600\n",
    "\n",
    "# Format and display\n",
    "duration_df = duration_summary.to_frame().reset_index()\n",
    "duration_df.columns = ['Classified Type', 'Total Duration (Hours)']\n",
    "duration_df['Total Duration (Hours)'] = duration_df['Total Duration (Hours)'].round(2)\n",
    "print(duration_df.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f53a5656-0fee-494d-8a20-2693ba581e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DataFrame loaded successfully from Excel.\n",
      "âœ… Classification complete.\n",
      "\n",
      "==================================================\n",
      "âœ… CLASSIFICATION VALIDATION RESULTS\n",
      "==================================================\n",
      "Total Programs Analyzed: 2994\n",
      "Agreement Rate:         46.53% (1393 Correct)\n",
      "Disagreement Rate:      53.47% (1601 Incorrect)\n",
      "\n",
      "| Model Classification vs. Ground Truth (Rows: Ground Truth) |\n",
      "| Ground Truth             | Highlights/Short Segment   | LIVE   | Other/Original Label   | Repeat   | All    |\n",
      "|:-------------------------|:---------------------------|:-------|:-----------------------|:---------|:-------|\n",
      "| Highlights/Short Segment | 22.00%                     | 0.00%  | 0.00%                  | 0.00%    | 10.65% |\n",
      "| LIVE                     | 0.76%                      | 64.75% | 7.22%                  | 4.11%    | 15.73% |\n",
      "| Other/Original Label     | 62.48%                     | 6.37%  | 25.26%                 | 9.77%    | 35.57% |\n",
      "| Repeat                   | 14.76%                     | 28.88% | 67.53%                 | 86.12%   | 38.04% |\n",
      "\n",
      "| Top Reasons for Disagreement |\n",
      "| Disagreement Reason                                        |   count |\n",
      "|:-----------------------------------------------------------|--------:|\n",
      "| Model=Highlights/Short Segment, Truth=Other/Original Label |     906 |\n",
      "| False Negative (Missed Repeat)                             |     345 |\n",
      "| False Positive (Incorrectly LIVE)                          |     227 |\n",
      "| Model=Repeat, Truth=Other/Original Label                   |      69 |\n",
      "| False Negative (Missed LIVE)                               |      54 |\n",
      "\n",
      "| Examples of Incorrect Classification |\n",
      "| Program Title                                         | Start Datetime UTC   | Duration_td     | Ground Truth         | Model Classification     | Disagreement Reason                                        |\n",
      "|:------------------------------------------------------|:---------------------|:----------------|:---------------------|:-------------------------|:-----------------------------------------------------------|\n",
      "| El Show de la F1        -O El Show de la F1        -O | 2025-07-04 01:00:00  | 0 days 01:00:00 | Other/Original Label | Highlights/Short Segment | Model=Highlights/Short Segment, Truth=Other/Original Label |\n",
      "| FORMULA 1 PRACTICAS(R)                                | 2025-07-04 19:00:03  | 0 days 01:09:26 | Repeat               | LIVE (Practice/Session)  | False Positive (Incorrectly LIVE)                          |\n",
      "| FORMULA 1 PRACTICAS(R2)                               | 2025-07-04 20:09:29  | 0 days 01:10:50 | Repeat               | LIVE (Practice/Session)  | False Positive (Incorrectly LIVE)                          |\n",
      "| FORMULA 1 PRACTICAS(R)                                | 2025-07-05 18:01:27  | 0 days 01:10:43 | Repeat               | LIVE (Practice/Session)  | False Positive (Incorrectly LIVE)                          |\n",
      "| FORMULA UNO CLASIFICA(R)                              | 2025-07-05 19:12:10  | 0 days 01:18:00 | Repeat               | LIVE (Practice/Session)  | False Positive (Incorrectly LIVE)                          |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BHRAJG2501\\AppData\\Local\\Temp\\1\\ipykernel_23500\\2184252450.py:196: FutureWarning:\n",
      "\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from datetime import datetime, time\n",
    "\n",
    "# --- 0. Data Loading ---\n",
    "# NOTE: This section relies on your successful loading of the Excel file.\n",
    "try:\n",
    "    df = pd.read_excel(\n",
    "        \"data/WF 3 F1-R12 - Great Britain.xlsx\",\n",
    "        sheet_name=\"Worksheet\",\n",
    "        header=5 \n",
    "    )\n",
    "    print(\"âœ… DataFrame loaded successfully from Excel.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ ERROR: File not found. Using dummy structure for logic demonstration.\")\n",
    "    # Create a dummy DataFrame with a variety of correct/incorrect classifications\n",
    "    df = pd.DataFrame({\n",
    "        'Program Title': ['P1 Live', 'P1 Live', 'P1 Highlights', 'P1 Live', 'Race Live', 'Race Live', 'Race Replay', 'Pre-Show'],\n",
    "        'Date (UTC/GMT)': pd.to_datetime(['2025-07-04', '2025-07-04', '2025-07-04', '2025-07-04', '2025-07-06', '2025-07-06', '2025-07-06', '2025-07-04']),\n",
    "        'Start (UTC)': [time(11, 30, 0), time(11, 35, 0), time(14, 0, 0), time(18, 0, 0), time(14, 0, 0), time(14, 15, 0), time(23, 0, 0), time(10, 30, 0)],\n",
    "        'Duration': ['01:30:00', '01:30:00', '00:45:00', '01:30:00', '02:00:00', '02:00:00', '02:00:00', '01:00:00'],\n",
    "        'Market': ['GB', 'FR', 'GB', 'DE', 'FR', 'GB', 'DE', 'FR'],\n",
    "        'Channel ID': [101.0, 102.0, 101.0, 101.0, 102.0, 101.0, 102.0, 101.0],\n",
    "        'Type of program': ['Live', 'Live', 'Highlights', 'Repeat', 'Live', 'Live', 'Repeat', 'Pre-Show'] # Ground Truth\n",
    "    })\n",
    "    \n",
    "if df.empty:\n",
    "    print(\"Cannot proceed with an empty DataFrame.\")\n",
    "    exit()\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 1. Define Live Schedule and Run Classification\n",
    "\n",
    "live_schedule = [\n",
    "    ('Practice 1', '4-Jul-2025', '11:30:00'),\n",
    "    ('Practice 2', '4-Jul-2025', '15:00:00'),\n",
    "    ('Practice 3', '5-Jul-2025', '10:30:00'),\n",
    "    ('Qualifying', '5-Jul-2025', '14:00:00'),\n",
    "    ('GRAND PRIX', '6-Jul-2025', '14:00:00')\n",
    "]\n",
    "\n",
    "live_events_dt = [pd.to_datetime(f\"{date} {time}\", format='%d-%b-%Y %H:%M:%S') for title, date, time in live_schedule]\n",
    "\n",
    "# Data Prep and Classification Logic (From previous step, simplified)\n",
    "def extract_time_string(time_value):\n",
    "    if pd.isna(time_value): return '00:00:00'\n",
    "    if isinstance(time_value, time): return time_value.strftime('%H:%M:%S')\n",
    "    if isinstance(time_value, datetime): return time_value.time().strftime('%H:%M:%S')\n",
    "    try:\n",
    "        return pd.to_datetime(str(time_value)).time().strftime('%H:%M:%S')\n",
    "    except: return '00:00:00'\n",
    "\n",
    "def parse_duration(duration_str):\n",
    "    if pd.isna(duration_str) or str(duration_str).strip() == '': return pd.Timedelta(seconds=0)\n",
    "    try:\n",
    "        parts = str(duration_str).split(':')\n",
    "        if len(parts) == 3:\n",
    "             h, m, s = map(int, parts)\n",
    "             return pd.Timedelta(hours=h, minutes=m, seconds=s)\n",
    "        if isinstance(duration_str, pd.Timedelta): return duration_str\n",
    "    except:\n",
    "        pass\n",
    "    return pd.Timedelta(seconds=0)\n",
    "\n",
    "df['Date (UTC/GMT)'] = pd.to_datetime(df['Date (UTC/GMT)'], errors='coerce')\n",
    "df['Clean_Time_UTC_Str'] = df['Start (UTC)'].apply(extract_time_string)\n",
    "df['Start Datetime UTC'] = pd.to_datetime(df['Date (UTC/GMT)'].dt.strftime('%Y-%m-%d') + ' ' + df['Clean_Time_UTC_Str'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "df['Duration_td'] = df['Duration'].apply(parse_duration)\n",
    "df = df.replace({pd.NaT: np.nan}) \n",
    "\n",
    "# Classification Parameters\n",
    "MIN_LIVE_RACE_QUALI_DURATION = pd.Timedelta(minutes=90) \n",
    "MIN_LIVE_PRACTICE_DURATION = pd.Timedelta(minutes=60)\n",
    "MAX_HIGHLIGHTS_DURATION = pd.Timedelta(minutes=60)\n",
    "LIVE_WINDOW_BEFORE = pd.Timedelta(hours=1) \n",
    "LIVE_THRESHOLD_AFTER = pd.Timedelta(hours=6) \n",
    "REPEAT_THRESHOLD_AFTER = pd.Timedelta(hours=12)\n",
    "\n",
    "def classify_program_title_agnostic(row):\n",
    "    start_dt_utc = row['Start Datetime UTC']\n",
    "    duration = row['Duration_td']\n",
    "    title = str(row['Program Title']).strip().split('(')[0].strip()\n",
    "\n",
    "    if pd.isna(start_dt_utc) or pd.isna(duration) or duration == pd.Timedelta(seconds=0):\n",
    "        return 'Unknown/No Duration'\n",
    "    \n",
    "    # --- 1. LIVE Classification ---\n",
    "    for live_dt in live_events_dt:\n",
    "        if (start_dt_utc >= live_dt - LIVE_WINDOW_BEFORE) and \\\n",
    "           (start_dt_utc <= live_dt + LIVE_THRESHOLD_AFTER):\n",
    "            \n",
    "            if duration >= MIN_LIVE_PRACTICE_DURATION:\n",
    "                if duration >= MIN_LIVE_RACE_QUALI_DURATION:\n",
    "                     return 'LIVE (Race/Quali)'\n",
    "                else:\n",
    "                    return 'LIVE (Practice/Session)'\n",
    "    \n",
    "    # --- 2. REPEAT Classification ---\n",
    "    for live_dt in live_events_dt:\n",
    "        if (start_dt_utc > live_dt + REPEAT_THRESHOLD_AFTER) and \\\n",
    "           (duration >= MIN_LIVE_PRACTICE_DURATION):\n",
    "            return 'Repeat Broadcast'\n",
    "\n",
    "    # --- 3. HIGHLIGHTS / SHORT SEGMENT Classification ---\n",
    "    if duration <= MAX_HIGHLIGHTS_DURATION:\n",
    "        if 'Highlights' in title or 'Review' in title or 'News' in title:\n",
    "             return title\n",
    "        return 'Highlights/Short Segment'\n",
    "                \n",
    "    return 'Other Long Segment'\n",
    "\n",
    "df['Model Classification'] = df.apply(classify_program_title_agnostic, axis=1)\n",
    "print(\"âœ… Classification complete.\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 2. Harmonize Categories\n",
    "\n",
    "# Normalize the ground truth 'Type of program' column to match the model's categories\n",
    "# This step is critical because 'Live' != 'LIVE (Race/Quali)' in string comparison.\n",
    "\n",
    "def harmonize_ground_truth(category):\n",
    "    category = str(category).strip().lower()\n",
    "    if category in ['live', 'live broadcast', 'race live', 'quali live']:\n",
    "        return 'LIVE'\n",
    "    elif category in ['repeat', 're-run', 'recap']:\n",
    "        return 'Repeat'\n",
    "    elif category in ['highlights', 'short segment', 'review', 'news', 'pre-show', 'post-show', 'magazine']:\n",
    "        return 'Highlights/Short Segment'\n",
    "    else:\n",
    "        # Catch all other labels (e.g., 'Unknown/No Duration', or specific program titles)\n",
    "        return 'Other/Original Label' \n",
    "\n",
    "# Create a harmonized version of the original column\n",
    "df['Ground Truth'] = df['Type of program'].apply(harmonize_ground_truth)\n",
    "\n",
    "# Harmonize Model Classification for easier comparison:\n",
    "df['Model Harmonized'] = df['Model Classification'].apply(lambda x: \n",
    "    'LIVE' if 'LIVE' in x else \n",
    "    ('Repeat' if 'Repeat' in x else \n",
    "     ('Highlights/Short Segment' if 'Highlights' in x or x == 'Formula 1 Highlights' else 'Other/Original Label')\n",
    "    )\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 3. Compare and Analyze ðŸ”¬\n",
    "\n",
    "# Calculate Agreement\n",
    "df['Agreement'] = np.where(df['Model Harmonized'] == df['Ground Truth'], 'Correct', 'Incorrect')\n",
    "\n",
    "# Total Metrics\n",
    "total_rows = len(df)\n",
    "correct_count = (df['Agreement'] == 'Correct').sum()\n",
    "incorrect_count = (df['Agreement'] == 'Incorrect').sum()\n",
    "\n",
    "# Reason for Discrepancy (Focus on key disagreement types)\n",
    "def get_disagreement_reason(row):\n",
    "    if row['Agreement'] == 'Correct':\n",
    "        return 'Match'\n",
    "    \n",
    "    model = row['Model Harmonized']\n",
    "    truth = row['Ground Truth']\n",
    "    \n",
    "    if truth == 'LIVE' and model != 'LIVE':\n",
    "        # Should be LIVE but wasn't caught by the time window (Program started too late/early or duration was wrong)\n",
    "        return 'False Negative (Missed LIVE)'\n",
    "    elif model == 'LIVE' and truth != 'LIVE':\n",
    "        # Was classified LIVE, but the original data says otherwise (Likely a strict local definition vs. our wide UTC window)\n",
    "        return 'False Positive (Incorrectly LIVE)'\n",
    "    elif truth == 'Repeat' and model != 'Repeat':\n",
    "        # Should be Repeat but was classified as \"Other Long Segment\" (Repeat threshold too strict)\n",
    "        return 'False Negative (Missed Repeat)'\n",
    "    elif truth == 'Highlights/Short Segment' and model == 'Other/Original Label':\n",
    "         # Original label was highly specific (e.g., 'Pre-Show'), missed by our general 'Highlights' logic\n",
    "         return f'Original Label Too Specific: {row[\"Type of program\"]}'\n",
    "    \n",
    "    return f'Model={model}, Truth={truth}'\n",
    "\n",
    "df['Disagreement Reason'] = df.apply(get_disagreement_reason, axis=1)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 4. Output Summary\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"âœ… CLASSIFICATION VALIDATION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. Overall Metrics\n",
    "print(f\"Total Programs Analyzed: {total_rows}\")\n",
    "print(f\"Agreement Rate:         {correct_count / total_rows:.2%} ({correct_count} Correct)\")\n",
    "print(f\"Disagreement Rate:      {incorrect_count / total_rows:.2%} ({incorrect_count} Incorrect)\")\n",
    "\n",
    "# 2. Confusion Matrix (Agreement by Harmonized Category)\n",
    "print(\"\\n| Model Classification vs. Ground Truth (Rows: Ground Truth) |\")\n",
    "agreement_matrix = pd.crosstab(df['Ground Truth'], df['Model Harmonized'], margins=True, normalize='columns')\n",
    "print(agreement_matrix.applymap(lambda x: f'{x:.2%}').to_markdown())\n",
    "\n",
    "\n",
    "# 3. Top Reasons for Disagreement\n",
    "print(\"\\n| Top Reasons for Disagreement |\")\n",
    "reason_summary = df[df['Agreement'] == 'Incorrect']['Disagreement Reason'].value_counts()\n",
    "print(reason_summary.head().to_frame().to_markdown())\n",
    "\n",
    "# 4. Example of Incorrect Classifications\n",
    "print(\"\\n| Examples of Incorrect Classification |\")\n",
    "incorrect_examples = df[df['Agreement'] == 'Incorrect'].head(5)\n",
    "print(incorrect_examples[['Program Title', 'Start Datetime UTC', 'Duration_td', 'Ground Truth', 'Model Classification', 'Disagreement Reason']].to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7017f661-2f96-45ba-ab96-68485eb44e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d91cf25-f39a-4344-8fb2-524db5f6564d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DataFrame loaded successfully from Excel.\n",
      "âœ… Model Classification complete.\n",
      "\n",
      "==================================================\n",
      "âœ… CLASSIFICATION VALIDATION RESULTS\n",
      "==================================================\n",
      "Total Programs Analyzed: 2994\n",
      "Agreement Rate:         46.53% (1393 Correct)\n",
      "Disagreement Rate:      53.47% (1601 Incorrect)\n",
      "\n",
      "| Model Classification vs. Ground Truth (Rows: Ground Truth) |\n",
      "| Ground Truth             | Highlights/Short Segment   | LIVE   | Other/Original Label   | Repeat   |\n",
      "|:-------------------------|:---------------------------|:-------|:-----------------------|:---------|\n",
      "| Highlights/Short Segment | 100.00%                    | 0.00%  | 0.00%                  | 0.00%    |\n",
      "| LIVE                     | 2.34%                      | 88.54% | 2.97%                  | 6.16%    |\n",
      "| Other/Original Label     | 85.07%                     | 3.85%  | 4.60%                  | 6.48%    |\n",
      "| Repeat                   | 18.79%                     | 16.33% | 11.50%                 | 53.38%   |\n",
      "| All                      | 48.43%                     | 21.51% | 6.48%                  | 23.58%   |\n",
      "\n",
      "| Top Reasons for Disagreement |\n",
      "| Disagreement Reason                                        |   count |\n",
      "|:-----------------------------------------------------------|--------:|\n",
      "| Model=Highlights/Short Segment, Truth=Other/Original Label |     906 |\n",
      "| False Negative (Missed Repeat)                             |     345 |\n",
      "| False Positive (Incorrectly LIVE)                          |     227 |\n",
      "| Model=Repeat, Truth=Other/Original Label                   |      69 |\n",
      "| False Negative (Missed LIVE)                               |      54 |\n",
      "\n",
      "| Examples of Incorrect Classification |\n",
      "| Program Title                                         | Start Datetime UTC   | Duration_td     | Ground Truth         | Model Classification     | Disagreement Reason                                        |\n",
      "|:------------------------------------------------------|:---------------------|:----------------|:---------------------|:-------------------------|:-----------------------------------------------------------|\n",
      "| El Show de la F1        -O El Show de la F1        -O | 2025-07-04 01:00:00  | 0 days 01:00:00 | Other/Original Label | Highlights/Short Segment | Model=Highlights/Short Segment, Truth=Other/Original Label |\n",
      "| FORMULA 1 PRACTICAS(R)                                | 2025-07-04 19:00:03  | 0 days 01:09:26 | Repeat               | LIVE (Practice/Session)  | False Positive (Incorrectly LIVE)                          |\n",
      "| FORMULA 1 PRACTICAS(R2)                               | 2025-07-04 20:09:29  | 0 days 01:10:50 | Repeat               | LIVE (Practice/Session)  | False Positive (Incorrectly LIVE)                          |\n",
      "| FORMULA 1 PRACTICAS(R)                                | 2025-07-05 18:01:27  | 0 days 01:10:43 | Repeat               | LIVE (Practice/Session)  | False Positive (Incorrectly LIVE)                          |\n",
      "| FORMULA UNO CLASIFICA(R)                              | 2025-07-05 19:12:10  | 0 days 01:18:00 | Repeat               | LIVE (Practice/Session)  | False Positive (Incorrectly LIVE)                          |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BHRAJG2501\\AppData\\Local\\Temp\\1\\ipykernel_23500\\3098083333.py:197: FutureWarning:\n",
      "\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from datetime import datetime, time\n",
    "\n",
    "# --- 0. Data Loading ---\n",
    "# NOTE: This section relies on your successful loading of the Excel file.\n",
    "try:\n",
    "    df = pd.read_excel(\n",
    "        \"data/WF 3 F1-R12 - Great Britain.xlsx\",\n",
    "        sheet_name=\"Worksheet\",\n",
    "        header=5 \n",
    "    )\n",
    "    print(\"âœ… DataFrame loaded successfully from Excel.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ ERROR: File not found. Using dummy structure for logic demonstration.\")\n",
    "    # Create a dummy DataFrame with a variety of correct/incorrect classifications\n",
    "    # Added a placeholder for the requested 'Magazine & Support' column\n",
    "    df = pd.DataFrame({\n",
    "        'Program Title': ['P1 Live', 'P1 Live', 'P1 Highlights', 'P1 Live', 'Race Live', 'Race Live', 'Race Replay', 'Pre-Show', 'Magazine'],\n",
    "        'Date (UTC/GMT)': pd.to_datetime(['2025-07-04', '2025-07-04', '2025-07-04', '2025-07-04', '2025-07-06', '2025-07-06', '2025-07-06', '2025-07-04', '2025-07-04']),\n",
    "        'Start (UTC)': [time(11, 30, 0), time(11, 35, 0), time(14, 0, 0), time(18, 0, 0), time(14, 0, 0), time(14, 15, 0), time(23, 0, 0), time(10, 30, 0), time(15, 0, 0)],\n",
    "        'Duration': ['01:30:00', '01:30:00', '00:45:00', '01:30:00', '02:00:00', '02:00:00', '02:00:00', '01:00:00', '00:45:00'],\n",
    "        'Market': ['GB', 'FR', 'GB', 'DE', 'FR', 'GB', 'DE', 'FR', 'GB'],\n",
    "        'Channel ID': [101.0, 102.0, 101.0, 101.0, 102.0, 101.0, 102.0, 101.0, 103.0],\n",
    "        'Type of program': ['Live', 'Live', 'Highlights', 'Repeat', 'Live', 'Live', 'Repeat', 'Pre-Show', 'Magazine'], # Ground Truth\n",
    "        'Magazine & Support': ['No', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes'] # Explicitly ignored column\n",
    "    })\n",
    "    \n",
    "if df.empty:\n",
    "    print(\"Cannot proceed with an empty DataFrame.\")\n",
    "    exit()\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 1. Define Live Schedule and Run Classification\n",
    "\n",
    "live_schedule = [\n",
    "    ('Practice 1', '4-Jul-2025', '11:30:00'),\n",
    "    ('Practice 2', '4-Jul-2025', '15:00:00'),\n",
    "    ('Practice 3', '5-Jul-2025', '10:30:00'),\n",
    "    ('Qualifying', '5-Jul-2025', '14:00:00'),\n",
    "    ('GRAND PRIX', '6-Jul-2025', '14:00:00')\n",
    "]\n",
    "\n",
    "live_events_dt = [pd.to_datetime(f\"{date} {time}\", format='%d-%b-%Y %H:%M:%S') for title, date, time in live_schedule]\n",
    "\n",
    "# Data Prep and Classification Logic (Re-used for consistency)\n",
    "def extract_time_string(time_value):\n",
    "    if pd.isna(time_value): return '00:00:00'\n",
    "    if isinstance(time_value, time): return time_value.strftime('%H:%M:%S')\n",
    "    if isinstance(time_value, datetime): return time_value.time().strftime('%H:%M:%S')\n",
    "    try:\n",
    "        return pd.to_datetime(str(time_value)).time().strftime('%H:%M:%S')\n",
    "    except: return '00:00:00'\n",
    "\n",
    "def parse_duration(duration_str):\n",
    "    if pd.isna(duration_str) or str(duration_str).strip() == '': return pd.Timedelta(seconds=0)\n",
    "    try:\n",
    "        parts = str(duration_str).split(':')\n",
    "        if len(parts) == 3:\n",
    "             h, m, s = map(int, parts)\n",
    "             return pd.Timedelta(hours=h, minutes=m, seconds=s)\n",
    "        if isinstance(duration_str, pd.Timedelta): return duration_str\n",
    "    except:\n",
    "        pass\n",
    "    return pd.Timedelta(seconds=0)\n",
    "\n",
    "df['Date (UTC/GMT)'] = pd.to_datetime(df['Date (UTC/GMT)'], errors='coerce')\n",
    "df['Clean_Time_UTC_Str'] = df['Start (UTC)'].apply(extract_time_string)\n",
    "df['Start Datetime UTC'] = pd.to_datetime(df['Date (UTC/GMT)'].dt.strftime('%Y-%m-%d') + ' ' + df['Clean_Time_UTC_Str'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "df['Duration_td'] = df['Duration'].apply(parse_duration)\n",
    "df = df.replace({pd.NaT: np.nan}) \n",
    "\n",
    "# Classification Parameters\n",
    "MIN_LIVE_RACE_QUALI_DURATION = pd.Timedelta(minutes=90) \n",
    "MIN_LIVE_PRACTICE_DURATION = pd.Timedelta(minutes=60)\n",
    "MAX_HIGHLIGHTS_DURATION = pd.Timedelta(minutes=60)\n",
    "LIVE_WINDOW_BEFORE = pd.Timedelta(hours=1) \n",
    "LIVE_THRESHOLD_AFTER = pd.Timedelta(hours=6) \n",
    "REPEAT_THRESHOLD_AFTER = pd.Timedelta(hours=12)\n",
    "\n",
    "def classify_program_title_agnostic(row):\n",
    "    start_dt_utc = row['Start Datetime UTC']\n",
    "    duration = row['Duration_td']\n",
    "    title = str(row['Program Title']).strip().split('(')[0].strip()\n",
    "\n",
    "    if pd.isna(start_dt_utc) or pd.isna(duration) or duration == pd.Timedelta(seconds=0):\n",
    "        return 'Unknown/No Duration'\n",
    "    \n",
    "    # --- 1. LIVE Classification ---\n",
    "    for live_dt in live_events_dt:\n",
    "        if (start_dt_utc >= live_dt - LIVE_WINDOW_BEFORE) and \\\n",
    "           (start_dt_utc <= live_dt + LIVE_THRESHOLD_AFTER):\n",
    "            \n",
    "            if duration >= MIN_LIVE_PRACTICE_DURATION:\n",
    "                if duration >= MIN_LIVE_RACE_QUALI_DURATION:\n",
    "                     return 'LIVE (Race/Quali)'\n",
    "                else:\n",
    "                    return 'LIVE (Practice/Session)'\n",
    "    \n",
    "    # --- 2. REPEAT Classification ---\n",
    "    for live_dt in live_events_dt:\n",
    "        if (start_dt_utc > live_dt + REPEAT_THRESHOLD_AFTER) and \\\n",
    "           (duration >= MIN_LIVE_PRACTICE_DURATION):\n",
    "            return 'Repeat Broadcast'\n",
    "\n",
    "    # --- 3. HIGHLIGHTS / SHORT SEGMENT Classification ---\n",
    "    if duration <= MAX_HIGHLIGHTS_DURATION:\n",
    "        if 'Highlights' in title or 'Review' in title or 'News' in title:\n",
    "             return title\n",
    "        return 'Highlights/Short Segment'\n",
    "                \n",
    "    return 'Other Long Segment'\n",
    "\n",
    "df['Model Classification'] = df.apply(classify_program_title_agnostic, axis=1)\n",
    "print(\"âœ… Model Classification complete.\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 2. Harmonize Categories for Comparison ðŸ¤\n",
    "\n",
    "# Normalize the original 'Type of program' column (Ground Truth)\n",
    "# We ONLY use the 'Type of program' column and ignore all others.\n",
    "def harmonize_ground_truth(category):\n",
    "    category = str(category).strip().lower()\n",
    "    if category in ['live', 'live broadcast', 'race live', 'quali live']:\n",
    "        return 'LIVE'\n",
    "    elif category in ['repeat', 're-run', 'rerun', 'recap']:\n",
    "        return 'Repeat'\n",
    "    # Group any short-form/pre-post-show content into one category\n",
    "    elif category in ['highlights', 'short segment', 'review', 'news', 'pre-show', 'post-show', 'magazine', 'support', 'other']:\n",
    "        return 'Highlights/Short Segment'\n",
    "    else:\n",
    "        # Catch all other specific or unexpected labels\n",
    "        return 'Other/Original Label' \n",
    "\n",
    "df['Ground Truth'] = df['Type of program'].apply(harmonize_ground_truth)\n",
    "\n",
    "# Harmonize Model Classification\n",
    "df['Model Harmonized'] = df['Model Classification'].apply(lambda x: \n",
    "    'LIVE' if 'LIVE' in x else \n",
    "    ('Repeat' if 'Repeat' in x else \n",
    "     ('Highlights/Short Segment' if 'Highlights' in x or x == 'Formula 1 Highlights' else 'Other/Original Label')\n",
    "    )\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 3. Compare and Analyze ðŸ”¬\n",
    "\n",
    "# Calculate Agreement\n",
    "df['Agreement'] = np.where(df['Model Harmonized'] == df['Ground Truth'], 'Correct', 'Incorrect')\n",
    "\n",
    "# Total Metrics\n",
    "total_rows = len(df)\n",
    "correct_count = (df['Agreement'] == 'Correct').sum()\n",
    "incorrect_count = (df['Agreement'] == 'Incorrect').sum()\n",
    "\n",
    "# Reason for Discrepancy\n",
    "def get_disagreement_reason(row):\n",
    "    if row['Agreement'] == 'Correct':\n",
    "        return 'Match'\n",
    "    \n",
    "    model = row['Model Harmonized']\n",
    "    truth = row['Ground Truth']\n",
    "    \n",
    "    if truth == 'LIVE' and model != 'LIVE':\n",
    "        # Should be LIVE (Ground Truth) but wasn't caught by Model (e.g., missed the time window)\n",
    "        return 'False Negative (Missed LIVE)'\n",
    "    elif model == 'LIVE' and truth != 'LIVE':\n",
    "        # Was classified LIVE by Model, but Ground Truth says otherwise (e.g., Model caught a long segment as LIVE)\n",
    "        return 'False Positive (Incorrectly LIVE)'\n",
    "    elif truth == 'Repeat' and model != 'Repeat':\n",
    "        # Should be Repeat but Model classified as \"Other Long Segment\" (Repeat threshold too strict)\n",
    "        return 'False Negative (Missed Repeat)'\n",
    "    elif model == 'Other/Original Label' and truth == 'Highlights/Short Segment':\n",
    "        # Ground Truth used a generic Highlights term, but Model put it in the catch-all\n",
    "         return 'Model Missed Short Segment'\n",
    "    \n",
    "    return f'Model={model}, Truth={truth}'\n",
    "\n",
    "df['Disagreement Reason'] = df.apply(get_disagreement_reason, axis=1)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 4. Output Summary\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"âœ… CLASSIFICATION VALIDATION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. Overall Metrics\n",
    "print(f\"Total Programs Analyzed: {total_rows}\")\n",
    "print(f\"Agreement Rate:         {correct_count / total_rows:.2%} ({correct_count} Correct)\")\n",
    "print(f\"Disagreement Rate:      {incorrect_count / total_rows:.2%} ({incorrect_count} Incorrect)\")\n",
    "\n",
    "# 2. Confusion Matrix (Agreement by Harmonized Category)\n",
    "print(\"\\n| Model Classification vs. Ground Truth (Rows: Ground Truth) |\")\n",
    "# Using normalize='index' shows, for a given true label (row), where the model's predictions (columns) fell.\n",
    "agreement_matrix = pd.crosstab(df['Ground Truth'], df['Model Harmonized'], margins=True, normalize='index') \n",
    "print(agreement_matrix.applymap(lambda x: f'{x:.2%}').to_markdown())\n",
    "\n",
    "\n",
    "# 3. Top Reasons for Disagreement\n",
    "print(\"\\n| Top Reasons for Disagreement |\")\n",
    "reason_summary = df[df['Agreement'] == 'Incorrect']['Disagreement Reason'].value_counts()\n",
    "print(reason_summary.head().to_frame().to_markdown())\n",
    "\n",
    "# 4. Example of Incorrect Classifications\n",
    "print(\"\\n| Examples of Incorrect Classification |\")\n",
    "incorrect_examples = df[df['Agreement'] == 'Incorrect'].head(5)\n",
    "print(incorrect_examples[['Program Title', 'Start Datetime UTC', 'Duration_td', 'Ground Truth', 'Model Classification', 'Disagreement Reason']].to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbff927f-8451-45aa-87ed-43398eeeccd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38d73445-ba19-4e69-8118-df30b1b8dfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DataFrame loaded successfully from Excel.\n",
      "âœ… Optimized Model Classification complete.\n",
      "\n",
      "==================================================\n",
      "âœ… CLASSIFICATION VALIDATION RESULTS (Optimized)\n",
      "==================================================\n",
      "Total Programs Analyzed: 2994\n",
      "Agreement Rate:         50.13% (1501 Correct)\n",
      "Disagreement Rate:      49.87% (1493 Incorrect)\n",
      "\n",
      "| Model Classification vs. Ground Truth (Rows: Ground Truth) |\n",
      "| Ground Truth             | Highlights/Short Segment   | LIVE   | Other/Original Label   | Repeat   |\n",
      "|:-------------------------|:---------------------------|:-------|:-----------------------|:---------|\n",
      "| Highlights/Short Segment | 100.00%                    | 0.00%  | 0.00%                  | 0.00%    |\n",
      "| LIVE                     | 2.34%                      | 88.54% | 2.97%                  | 6.16%    |\n",
      "| Other/Original Label     | 85.07%                     | 3.47%  | 4.60%                  | 6.85%    |\n",
      "| Repeat                   | 18.44%                     | 9.75%  | 8.96%                  | 62.86%   |\n",
      "| All                      | 48.30%                     | 18.87% | 5.51%                  | 27.32%   |\n",
      "\n",
      "| Top Reasons for Disagreement |\n",
      "| Disagreement Reason                                        |   count |\n",
      "|:-----------------------------------------------------------|--------:|\n",
      "| Model=Highlights/Short Segment, Truth=Other/Original Label |     906 |\n",
      "| False Negative (Missed Repeat)                             |     312 |\n",
      "| False Positive (Incorrectly LIVE)                          |     148 |\n",
      "| False Positive (Incorrectly Repeat)                        |      73 |\n",
      "| False Negative (Missed LIVE)                               |      54 |\n",
      "\n",
      "| Examples of Incorrect Classification |\n",
      "| Program Title                                         | Start Datetime UTC   | Duration_td     | Ground Truth         | Model Classification     | Disagreement Reason                                        |\n",
      "|:------------------------------------------------------|:---------------------|:----------------|:---------------------|:-------------------------|:-----------------------------------------------------------|\n",
      "| El Show de la F1        -O El Show de la F1        -O | 2025-07-04 01:00:00  | 0 days 01:00:00 | Other/Original Label | Highlights/Short Segment | Model=Highlights/Short Segment, Truth=Other/Original Label |\n",
      "| -                                                     | 2025-07-05 11:30:00  | 0 days 02:00:00 | Other/Original Label | LIVE (Race/Quali)        | False Positive (Incorrectly LIVE)                          |\n",
      "| -                                                     | 2025-07-05 13:30:00  | 0 days 03:00:00 | Other/Original Label | LIVE (Race/Quali)        | False Positive (Incorrectly LIVE)                          |\n",
      "| -                                                     | 2025-07-05 16:30:00  | 0 days 03:00:00 | Other/Original Label | LIVE (Race/Quali)        | False Positive (Incorrectly LIVE)                          |\n",
      "| -                                                     | 2025-07-05 19:30:00  | 0 days 02:00:00 | Other/Original Label | Repeat Broadcast         | False Positive (Incorrectly Repeat)                        |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BHRAJG2501\\AppData\\Local\\Temp\\1\\ipykernel_23500\\507366535.py:208: FutureWarning:\n",
      "\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from datetime import datetime, time\n",
    "\n",
    "# --- 0. Data Loading ---\n",
    "# NOTE: This section relies on your successful loading of the Excel file.\n",
    "try:\n",
    "    df = pd.read_excel(\n",
    "        \"data/WF 3 F1-R12 - Great Britain.xlsx\",\n",
    "        sheet_name=\"Worksheet\",\n",
    "        header=5 \n",
    "    )\n",
    "    print(\"âœ… DataFrame loaded successfully from Excel.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ ERROR: File not found. Using dummy structure for logic demonstration.\")\n",
    "    # Create a dummy DataFrame with data designed to challenge the previous logic\n",
    "    df = pd.DataFrame({\n",
    "        'Program Title': ['P1 Live', 'P1 Live', 'P1 Highlights', 'Pre-Show', 'Race Live', 'Race Replay', 'Magazine Show', 'F1 News'],\n",
    "        'Date (UTC/GMT)': pd.to_datetime(['2025-07-04', '2025-07-04', '2025-07-04', '2025-07-04', '2025-07-06', '2025-07-06', '2025-07-06', '2025-07-06']),\n",
    "        # The 'Start (UTC)' times are key: 11:30 (Live), 11:35 (Live), 14:00 (Post-Show), 10:30 (Pre-Show), 14:00 (Live), 23:00 (Repeat), 10:00 (Next Day Support)\n",
    "        'Start (UTC)': [time(11, 30, 0), time(11, 35, 0), time(14, 0, 0), time(10, 30, 0), time(14, 0, 0), time(23, 0, 0), time(10, 0, 0), time(12, 0, 0)],\n",
    "        'Duration': ['01:30:00', '01:30:00', '00:45:00', '01:00:00', '02:00:00', '02:00:00', '01:30:00', '00:30:00'],\n",
    "        'Type of program': ['Live', 'Live', 'Highlights', 'Pre-Show', 'Live', 'Repeat', 'Magazine', 'News'], # Ground Truth\n",
    "    })\n",
    "    \n",
    "if df.empty:\n",
    "    print(\"Cannot proceed with an empty DataFrame.\")\n",
    "    exit()\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 1. Define Live Schedule and Run Classification\n",
    "\n",
    "live_schedule = [\n",
    "    ('Practice 1', '4-Jul-2025', '11:30:00'),\n",
    "    ('Practice 2', '4-Jul-2025', '15:00:00'),\n",
    "    ('Practice 3', '5-Jul-2025', '10:30:00'),\n",
    "    ('Qualifying', '5-Jul-2025', '14:00:00'),\n",
    "    ('GRAND PRIX', '6-Jul-2025', '14:00:00')\n",
    "]\n",
    "\n",
    "live_events_dt = [pd.to_datetime(f\"{date} {time}\", format='%d-%b-%Y %H:%M:%S') for title, date, time in live_schedule]\n",
    "\n",
    "# Data Prep and Classification Logic (Re-used for consistency)\n",
    "def extract_time_string(time_value):\n",
    "    if pd.isna(time_value): return '00:00:00'\n",
    "    if isinstance(time_value, time): return time_value.strftime('%H:%M:%S')\n",
    "    if isinstance(time_value, datetime): return time_value.time().strftime('%H:%M:%S')\n",
    "    try:\n",
    "        return pd.to_datetime(str(time_value)).time().strftime('%H:%M:%S')\n",
    "    except: return '00:00:00'\n",
    "\n",
    "def parse_duration(duration_str):\n",
    "    if pd.isna(duration_str) or str(duration_str).strip() == '': return pd.Timedelta(seconds=0)\n",
    "    try:\n",
    "        parts = str(duration_str).split(':')\n",
    "        if len(parts) == 3:\n",
    "             h, m, s = map(int, parts)\n",
    "             return pd.Timedelta(hours=h, minutes=m, seconds=s)\n",
    "        if isinstance(duration_str, pd.Timedelta): return duration_str\n",
    "    except:\n",
    "        pass\n",
    "    return pd.Timedelta(seconds=0)\n",
    "\n",
    "df['Date (UTC/GMT)'] = pd.to_datetime(df['Date (UTC/GMT)'], errors='coerce')\n",
    "df['Clean_Time_UTC_Str'] = df['Start (UTC)'].apply(extract_time_string)\n",
    "df['Start Datetime UTC'] = pd.to_datetime(df['Date (UTC/GMT)'].dt.strftime('%Y-%m-%d') + ' ' + df['Clean_Time_UTC_Str'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "df['Duration_td'] = df['Duration'].apply(parse_duration)\n",
    "df = df.replace({pd.NaT: np.nan}) \n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 2. Optimized Classification Parameters (Based on Improvement Rationale)\n",
    "\n",
    "MIN_LIVE_RACE_QUALI_DURATION = pd.Timedelta(minutes=90) \n",
    "MIN_LIVE_PRACTICE_DURATION = pd.Timedelta(minutes=60)\n",
    "MAX_HIGHLIGHTS_DURATION = pd.Timedelta(minutes=60) # Still used as a hard limit for short segments\n",
    "\n",
    "# NEW OPTIMIZED WINDOWS:\n",
    "# 1. Narrow the LIVE post-event window to reduce False Positives\n",
    "LIVE_WINDOW_BEFORE = pd.Timedelta(hours=1)\n",
    "LIVE_THRESHOLD_AFTER = pd.Timedelta(hours=4) # REDUCED from 6 hours to 4 hours (to minimize False Positives)\n",
    "\n",
    "# 2. Narrow the Repeat threshold to catch more Missed Repeats\n",
    "REPEAT_THRESHOLD_START = LIVE_THRESHOLD_AFTER # Repeat only if it starts AFTER the live window ends\n",
    "REPEAT_THRESHOLD_AFTER = pd.Timedelta(hours=6) # REDUCED from 12 hours to 6 hours (to increase True Repeats)\n",
    "\n",
    "# Known support/magazine keywords to improve short/long support classification\n",
    "SUPPORT_KEYWORDS = ['highlights', 'review', 'news', 'magazine', 'pre-show', 'post-show']\n",
    "\n",
    "\n",
    "def classify_program_optimized(row):\n",
    "    start_dt_utc = row['Start Datetime UTC']\n",
    "    duration = row['Duration_td']\n",
    "    title = str(row['Program Title']).strip().split('(')[0].strip().lower()\n",
    "\n",
    "    if pd.isna(start_dt_utc) or pd.isna(duration) or duration == pd.Timedelta(seconds=0):\n",
    "        return 'Unknown/No Duration'\n",
    "    \n",
    "    # --- 1. LIVE Classification (Time Proximity + Duration ONLY) ---\n",
    "    for live_dt in live_events_dt:\n",
    "        if (start_dt_utc >= live_dt - LIVE_WINDOW_BEFORE) and \\\n",
    "           (start_dt_utc <= live_dt + LIVE_THRESHOLD_AFTER):\n",
    "            \n",
    "            if duration >= MIN_LIVE_PRACTICE_DURATION:\n",
    "                if duration >= MIN_LIVE_RACE_QUALI_DURATION:\n",
    "                     return 'LIVE (Race/Quali)'\n",
    "                else:\n",
    "                    return 'LIVE (Practice/Session)'\n",
    "    \n",
    "    # --- 2. REPEAT Classification (Starts Much Later + Long Duration) ---\n",
    "    for live_dt in live_events_dt:\n",
    "        # Check if it starts after the strict live window AND before the next day\n",
    "        if (start_dt_utc > live_dt + REPEAT_THRESHOLD_AFTER) and \\\n",
    "           (duration >= MIN_LIVE_PRACTICE_DURATION):\n",
    "            return 'Repeat Broadcast'\n",
    "\n",
    "    # --- 3. HIGHLIGHTS / SHORT SEGMENT (Duration Check) ---\n",
    "    # Prioritize short segments based on duration or keywords\n",
    "    \n",
    "    is_support_title = any(keyword in title for keyword in SUPPORT_KEYWORDS)\n",
    "    \n",
    "    if duration <= MAX_HIGHLIGHTS_DURATION:\n",
    "        # If it's a short duration, classify it generally as a short segment\n",
    "        if is_support_title:\n",
    "             return 'Short Support (Title Match)' # Specific label helps trace\n",
    "        return 'Highlights/Short Segment'\n",
    "    \n",
    "    # --- 4. CATCH-ALL FOR MISSED LONG SEGMENTS ---\n",
    "    # If the duration is long (>60 min) AND it wasn't LIVE or REPEAT, classify as long support\n",
    "    if duration > MAX_HIGHLIGHTS_DURATION and is_support_title:\n",
    "        return 'Support Content (>60 min)'\n",
    "        \n",
    "    return 'Other Long Segment'\n",
    "\n",
    "df['Model Classification'] = df.apply(classify_program_optimized, axis=1)\n",
    "print(\"âœ… Optimized Model Classification complete.\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 3. Harmonize Categories for Comparison ðŸ¤\n",
    "\n",
    "# Normalize the original 'Type of program' column (Ground Truth)\n",
    "def harmonize_ground_truth(category):\n",
    "    category = str(category).strip().lower()\n",
    "    if category in ['live', 'live broadcast', 'race live', 'quali live']:\n",
    "        return 'LIVE'\n",
    "    elif category in ['repeat', 're-run', 'rerun', 'recap']:\n",
    "        return 'Repeat'\n",
    "    # Group ALL support/filler types into the general Highlights/Short Segment category\n",
    "    elif category in ['highlights', 'short segment', 'review', 'news', 'pre-show', 'post-show', 'magazine', 'support', 'other', 'f1 news']:\n",
    "        return 'Highlights/Short Segment'\n",
    "    else:\n",
    "        return 'Other/Original Label' \n",
    "\n",
    "df['Ground Truth'] = df['Type of program'].apply(harmonize_ground_truth)\n",
    "\n",
    "# Harmonize Model Classification\n",
    "df['Model Harmonized'] = df['Model Classification'].apply(lambda x: \n",
    "    'LIVE' if 'LIVE' in x else \n",
    "    ('Repeat' if 'Repeat' in x else \n",
    "     ('Highlights/Short Segment' if 'Highlights' in x or 'Short Support' in x or 'Support Content' in x else 'Other/Original Label')\n",
    "    )\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 4. Compare and Analyze ðŸ”¬\n",
    "\n",
    "# Calculate Agreement\n",
    "df['Agreement'] = np.where(df['Model Harmonized'] == df['Ground Truth'], 'Correct', 'Incorrect')\n",
    "\n",
    "# Total Metrics\n",
    "total_rows = len(df)\n",
    "correct_count = (df['Agreement'] == 'Correct').sum()\n",
    "incorrect_count = (df['Agreement'] == 'Incorrect').sum()\n",
    "\n",
    "# Reason for Discrepancy\n",
    "def get_disagreement_reason(row):\n",
    "    if row['Agreement'] == 'Correct': return 'Match'\n",
    "    model = row['Model Harmonized']\n",
    "    truth = row['Ground Truth']\n",
    "    \n",
    "    if truth == 'LIVE' and model != 'LIVE': return 'False Negative (Missed LIVE)'\n",
    "    if model == 'LIVE' and truth != 'LIVE': return 'False Positive (Incorrectly LIVE)'\n",
    "    if truth == 'Repeat' and model != 'Repeat': return 'False Negative (Missed Repeat)'\n",
    "    if model == 'Repeat' and truth != 'Repeat': return 'False Positive (Incorrectly Repeat)'\n",
    "    \n",
    "    # Catch cases where the model incorrectly classified a short segment as the final \"Other\" bucket\n",
    "    if model == 'Other/Original Label' and truth == 'Highlights/Short Segment':\n",
    "         return 'Model Missed Short Segment'\n",
    "    \n",
    "    return f'Model={model}, Truth={truth}'\n",
    "\n",
    "df['Disagreement Reason'] = df.apply(get_disagreement_reason, axis=1)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 5. Output Summary\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"âœ… CLASSIFICATION VALIDATION RESULTS (Optimized)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. Overall Metrics\n",
    "print(f\"Total Programs Analyzed: {total_rows}\")\n",
    "print(f\"Agreement Rate:         {correct_count / total_rows:.2%} ({correct_count} Correct)\")\n",
    "print(f\"Disagreement Rate:      {incorrect_count / total_rows:.2%} ({incorrect_count} Incorrect)\")\n",
    "\n",
    "# 2. Confusion Matrix (Agreement by Harmonized Category)\n",
    "print(\"\\n| Model Classification vs. Ground Truth (Rows: Ground Truth) |\")\n",
    "agreement_matrix = pd.crosstab(df['Ground Truth'], df['Model Harmonized'], margins=True, normalize='index') \n",
    "print(agreement_matrix.applymap(lambda x: f'{x:.2%}').to_markdown())\n",
    "\n",
    "\n",
    "# 3. Top Reasons for Disagreement\n",
    "print(\"\\n| Top Reasons for Disagreement |\")\n",
    "reason_summary = df[df['Agreement'] == 'Incorrect']['Disagreement Reason'].value_counts()\n",
    "print(reason_summary.head().to_frame().to_markdown())\n",
    "\n",
    "# 4. Example of Incorrect Classifications\n",
    "print(\"\\n| Examples of Incorrect Classification |\")\n",
    "incorrect_examples = df[df['Agreement'] == 'Incorrect'].head(5)\n",
    "print(incorrect_examples[['Program Title', 'Start Datetime UTC', 'Duration_td', 'Ground Truth', 'Model Classification', 'Disagreement Reason']].to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644e5d2a-4005-4c42-9977-7aa749258dce",
   "metadata": {},
   "source": [
    "FOCUS ON LIVE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18435627-b1da-4bef-a2f8-504c12b2d5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DataFrame loaded successfully from Excel.\n",
      "âœ… Model Classification (LIVE vs. NOT LIVE) complete.\n",
      "\n",
      "==================================================\n",
      "ðŸŽ¯ LIVE CLASSIFICATION PERFORMANCE\n",
      "==================================================\n",
      "Total Programs Analyzed: 2994\n",
      "Total True LIVE Events:  471\n",
      "Total NOT LIVE Events:   2523\n",
      "\n",
      "| Metric | Value |\n",
      "|:---|:---|\n",
      "| **Overall Accuracy** | 94.76% |\n",
      "| **Precision (Model)**| 80.19% |\n",
      "| **Recall (Model)** | 88.54% |\n",
      "| **False Positives (FP)** | 103 |\n",
      "| **False Negatives (FN)** | 54 |\n",
      "\n",
      "| Confusion Matrix |\n",
      "| Ground Truth   |   LIVE |   NOT LIVE |\n",
      "|:---------------|-------:|-----------:|\n",
      "| LIVE           |    417 |         54 |\n",
      "| NOT LIVE       |    103 |       2420 |\n",
      "\n",
      "| Examples of Incorrect Classification |\n",
      "| Program Title   | Start Datetime UTC   | Duration_td     | Ground Truth   | Model Classification   |\n",
      "|:----------------|:---------------------|:----------------|:---------------|:-----------------------|\n",
      "| -               | 2025-07-05 11:30:00  | 0 days 02:00:00 | NOT LIVE       | LIVE                   |\n",
      "| -               | 2025-07-05 13:30:00  | 0 days 03:00:00 | NOT LIVE       | LIVE                   |\n",
      "| -               | 2025-07-05 16:30:00  | 0 days 03:00:00 | NOT LIVE       | LIVE                   |\n",
      "| -               | 2025-07-06 14:00:00  | 0 days 02:00:00 | NOT LIVE       | LIVE                   |\n",
      "| -               | 2025-07-04 16:15:00  | 0 days 01:00:00 | NOT LIVE       | LIVE                   |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from datetime import datetime, time\n",
    "\n",
    "# --- 0. Data Loading ---\n",
    "# NOTE: This section relies on your successful loading of the Excel file.\n",
    "try:\n",
    "    df = pd.read_excel(\n",
    "        \"data/WF 3 F1-R12 - Great Britain.xlsx\",\n",
    "        sheet_name=\"Worksheet\",\n",
    "        header=5 \n",
    "    )\n",
    "    print(\"âœ… DataFrame loaded successfully from Excel.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ ERROR: File not found. Using dummy structure for logic demonstration.\")\n",
    "    # Dummy data tailored to test the LIVE boundary conditions\n",
    "    df = pd.DataFrame({\n",
    "        'Program Title': ['P1 Live', 'P1 Live', 'Post-Race Analysis', 'P1 Delayed', 'Race Live', 'Race Pre-Show', 'Race Replay', 'News'],\n",
    "        'Date (UTC/GMT)': pd.to_datetime(['2025-07-04', '2025-07-04', '2025-07-04', '2025-07-04', '2025-07-06', '2025-07-06', '2025-07-06', '2025-07-06']),\n",
    "        # P1 official start is 11:30. Race official start is 14:00.\n",
    "        'Start (UTC)': [time(11, 30, 0), time(11, 45, 0), time(14, 0, 0), time(18, 0, 0), time(14, 0, 0), time(13, 0, 0), time(20, 0, 0), time(18, 0, 0)],\n",
    "        'Duration': ['01:30:00', '01:30:00', '01:30:00', '01:30:00', '02:00:00', '01:00:00', '02:00:00', '00:30:00'],\n",
    "        'Type of program': ['Live', 'Live', 'Pre-Show', 'Repeat', 'Live', 'Pre-Show', 'Repeat', 'News'], # Ground Truth\n",
    "    })\n",
    "    \n",
    "if df.empty:\n",
    "    print(\"Cannot proceed with an empty DataFrame.\")\n",
    "    exit()\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 1. Data Preparation and Schedule Definition ðŸ—“ï¸\n",
    "\n",
    "live_schedule = [\n",
    "    ('Practice 1', '4-Jul-2025', '11:30:00'),\n",
    "    ('Practice 2', '4-Jul-2025', '15:00:00'),\n",
    "    ('Practice 3', '5-Jul-2025', '10:30:00'),\n",
    "    ('Qualifying', '5-Jul-2025', '14:00:00'),\n",
    "    ('GRAND PRIX', '6-Jul-2025', '14:00:00')\n",
    "]\n",
    "\n",
    "live_events_dt = [pd.to_datetime(f\"{date} {time}\", format='%d-%b-%Y %H:%M:%S') for title, date, time in live_schedule]\n",
    "\n",
    "# Re-run essential data cleaning columns\n",
    "def extract_time_string(time_value):\n",
    "    if pd.isna(time_value): return '00:00:00'\n",
    "    if isinstance(time_value, time): return time_value.strftime('%H:%M:%S')\n",
    "    if isinstance(time_value, datetime): return time_value.time().strftime('%H:%M:%S')\n",
    "    try: return pd.to_datetime(str(time_value)).time().strftime('%H:%M:%S')\n",
    "    except: return '00:00:00'\n",
    "\n",
    "def parse_duration(duration_str):\n",
    "    if pd.isna(duration_str) or str(duration_str).strip() == '': return pd.Timedelta(seconds=0)\n",
    "    try:\n",
    "        h, m, s = map(int, str(duration_str).split(':'))\n",
    "        return pd.Timedelta(hours=h, minutes=m, seconds=s)\n",
    "    except: return pd.Timedelta(seconds=0)\n",
    "\n",
    "df['Date (UTC/GMT)'] = pd.to_datetime(df['Date (UTC/GMT)'], errors='coerce')\n",
    "df['Clean_Time_UTC_Str'] = df['Start (UTC)'].apply(extract_time_string)\n",
    "df['Start Datetime UTC'] = pd.to_datetime(df['Date (UTC/GMT)'].dt.strftime('%Y-%m-%d') + ' ' + df['Clean_Time_UTC_Str'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "df['Duration_td'] = df['Duration'].apply(parse_duration)\n",
    "df = df.replace({pd.NaT: np.nan}) \n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 2. Optimized LIVE Classification Logic ðŸŽ¯\n",
    "\n",
    "# OPTIMIZED LIVE PARAMETERS\n",
    "MIN_LIVE_RACE_QUALI_DURATION = pd.Timedelta(minutes=90) \n",
    "MIN_LIVE_PRACTICE_DURATION = pd.Timedelta(minutes=60)\n",
    "\n",
    "# ðŸ”‘ CRUCIAL CHANGE: Tighten the post-event window to reduce False Positives\n",
    "LIVE_WINDOW_BEFORE = pd.Timedelta(hours=1)      # 1 hour pre-show buffer\n",
    "LIVE_THRESHOLD_AFTER = pd.Timedelta(minutes=150) # Reduced to 2.5 hours post-official-start\n",
    "\n",
    "def classify_live_only(row):\n",
    "    start_dt_utc = row['Start Datetime UTC']\n",
    "    duration = row['Duration_td']\n",
    "\n",
    "    if pd.isna(start_dt_utc) or pd.isna(duration) or duration == pd.Timedelta(seconds=0):\n",
    "        return 'NOT LIVE'\n",
    "    \n",
    "    # Check against ALL scheduled live times\n",
    "    for live_dt in live_events_dt:\n",
    "        # Check if program starts within the STRICT live window (1hr before, 2.5hrs after)\n",
    "        if (start_dt_utc >= live_dt - LIVE_WINDOW_BEFORE) and \\\n",
    "           (start_dt_utc <= live_dt + LIVE_THRESHOLD_AFTER):\n",
    "            \n",
    "            # Check for minimum required duration for a session to be considered a 'main' broadcast\n",
    "            if duration >= MIN_LIVE_PRACTICE_DURATION:\n",
    "                return 'LIVE'\n",
    "    \n",
    "    return 'NOT LIVE'\n",
    "\n",
    "df['Model Classification'] = df.apply(classify_live_only, axis=1)\n",
    "print(\"âœ… Model Classification (LIVE vs. NOT LIVE) complete.\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 3. Harmonize and Validate ðŸ“ˆ\n",
    "\n",
    "# Normalize the original 'Type of program' column to a simple LIVE / NOT LIVE\n",
    "def harmonize_ground_truth_live_only(category):\n",
    "    category = str(category).strip().lower()\n",
    "    if category in ['live', 'live broadcast', 'race live', 'quali live']:\n",
    "        return 'LIVE'\n",
    "    return 'NOT LIVE' # Everything else is NOT LIVE for this comparison\n",
    "\n",
    "df['Ground Truth'] = df['Type of program'].apply(harmonize_ground_truth_live_only)\n",
    "\n",
    "# Calculate Agreement\n",
    "df['Agreement'] = np.where(df['Model Classification'] == df['Ground Truth'], 'Correct', 'Incorrect')\n",
    "\n",
    "# Calculate Metrics for LIVE vs. NOT LIVE performance\n",
    "true_live = (df['Ground Truth'] == 'LIVE').sum()\n",
    "true_not_live = (df['Ground Truth'] == 'NOT LIVE').sum()\n",
    "\n",
    "TP = ((df['Ground Truth'] == 'LIVE') & (df['Model Classification'] == 'LIVE')).sum()       # True Positives\n",
    "FP = ((df['Ground Truth'] == 'NOT LIVE') & (df['Model Classification'] == 'LIVE')).sum()   # False Positives\n",
    "FN = ((df['Ground Truth'] == 'LIVE') & (df['Model Classification'] == 'NOT LIVE')).sum()   # False Negatives\n",
    "TN = ((df['Ground Truth'] == 'NOT LIVE') & (df['Model Classification'] == 'NOT LIVE')).sum() # True Negatives\n",
    "\n",
    "# Safety check for division by zero\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "accuracy = (TP + TN) / len(df)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 4. Output Summary\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸŽ¯ LIVE CLASSIFICATION PERFORMANCE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Total Programs Analyzed: {len(df)}\")\n",
    "print(f\"Total True LIVE Events:  {true_live}\")\n",
    "print(f\"Total NOT LIVE Events:   {true_not_live}\")\n",
    "\n",
    "print(\"\\n| Metric | Value |\")\n",
    "print(\"|:---|:---|\")\n",
    "print(f\"| **Overall Accuracy** | {accuracy:.2%} |\")\n",
    "print(f\"| **Precision (Model)**| {precision:.2%} |\")\n",
    "print(f\"| **Recall (Model)** | {recall:.2%} |\")\n",
    "print(f\"| **False Positives (FP)** | {FP} |\")\n",
    "print(f\"| **False Negatives (FN)** | {FN} |\")\n",
    "\n",
    "print(\"\\n| Confusion Matrix |\")\n",
    "confusion_matrix = pd.crosstab(df['Ground Truth'], df['Model Classification'], margins=False)\n",
    "print(confusion_matrix.to_markdown())\n",
    "\n",
    "print(\"\\n| Examples of Incorrect Classification |\")\n",
    "incorrect_examples = df[df['Agreement'] == 'Incorrect'].head(5)\n",
    "print(incorrect_examples[['Program Title', 'Start Datetime UTC', 'Duration_td', 'Ground Truth', 'Model Classification']].to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee15209c-64fc-4ca6-9f28-d1e515c6180a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Extracted 54 False Negative rows (Missed LIVE events).\n",
      "\n",
      "--- False Negatives (Missed LIVE Events) DataFrame ---\n",
      "| Program Title                           | Market        |   Channel ID | Start Datetime UTC   | Duration_td     | Ground Truth   | Model Classification   |\n",
      "|:----------------------------------------|:--------------|-------------:|:---------------------|:----------------|:---------------|:-----------------------|\n",
      "| THE F1 SHOW                             | Ireland       |        38443 | 2025-07-05 10:15:38  | 0 days 00:55:40 | LIVE           | NOT LIVE               |\n",
      "| FORMULA 1 -L 2025                       | Mexico        |         2854 | 2025-07-04 11:25:00  | 0 days 00:35:00 | LIVE           | NOT LIVE               |\n",
      "| THE F1 SHOW                             | UK            |        38443 | 2025-07-05 10:15:38  | 0 days 00:55:40 | LIVE           | NOT LIVE               |\n",
      "| -                                       | Vietnam       |         4425 | 2025-07-04 11:20:00  | 0 days 00:30:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Albania       |          nan | 2025-07-05 00:00:00  | 0 days 01:20:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Albania       |          nan | 2025-07-06 00:00:00  | 0 days 02:20:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | China         |          nan | 2025-07-04 00:00:00  | 0 days 01:30:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | China         |          nan | 2025-07-04 00:00:00  | 0 days 01:30:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | China         |          nan | 2025-07-05 00:00:00  | 0 days 01:00:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | China         |          nan | 2025-07-05 00:00:00  | 0 days 01:00:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | China         |          nan | 2025-07-06 00:00:00  | 0 days 02:00:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Estonia       |          nan | 2025-07-04 00:00:00  | 0 days 01:15:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Estonia       |          nan | 2025-07-04 00:00:00  | 0 days 01:15:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Estonia       |          nan | 2025-07-05 00:00:00  | 0 days 01:15:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Estonia       |          nan | 2025-07-05 00:00:00  | 0 days 01:50:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Estonia       |          nan | 2025-07-06 00:00:00  | 0 days 03:15:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Lithuania     |          nan | 2025-07-04 00:00:00  | 0 days 01:15:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Lithuania     |          nan | 2025-07-04 00:00:00  | 0 days 01:15:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Lithuania     |          nan | 2025-07-05 00:00:00  | 0 days 01:15:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Lithuania     |          nan | 2025-07-05 00:00:00  | 0 days 01:50:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Lithuania     |          nan | 2025-07-06 00:00:00  | 0 days 03:15:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Latvia        |          nan | 2025-07-04 00:00:00  | 0 days 01:15:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Latvia        |          nan | 2025-07-04 00:00:00  | 0 days 01:15:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Latvia        |          nan | 2025-07-05 00:00:00  | 0 days 01:15:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Latvia        |          nan | 2025-07-05 00:00:00  | 0 days 01:50:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Latvia        |          nan | 2025-07-06 00:00:00  | 0 days 03:15:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Netherlands   |          nan | 2025-07-04 00:00:00  | 0 days 01:10:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Netherlands   |          nan | 2025-07-04 00:00:00  | 0 days 01:10:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Netherlands   |          nan | 2025-07-04 00:00:00  | 0 days 01:53:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Netherlands   |          nan | 2025-07-04 00:00:00  | 0 days 01:53:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Netherlands   |          nan | 2025-07-05 00:00:00  | 0 days 01:10:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Netherlands   |          nan | 2025-07-05 00:00:00  | 0 days 02:45:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Netherlands   |          nan | 2025-07-06 00:00:00  | 0 days 03:45:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Pan-Carribean |          nan | 2025-07-04 00:00:00  | 0 days 01:00:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Pan-Carribean |          nan | 2025-07-04 00:00:00  | 0 days 01:00:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Pan-Carribean |          nan | 2025-07-05 00:00:00  | 0 days 01:00:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Pan-Carribean |          nan | 2025-07-05 00:00:00  | 0 days 01:30:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Pan-Carribean |          nan | 2025-07-06 00:00:00  | 0 days 02:00:00 | LIVE           | NOT LIVE               |\n",
      "| FORMULA 1 -L 2025                       | Mexico        |          nan | 2025-07-06 00:00:00  | 0 days 02:00:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Australia     |         6095 | 2025-07-06 15:45:21  | 0 days 00:14:38 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Australia     |         6095 | 2025-07-07 16:00:00  | 0 days 00:22:53 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Myanmar       |          nan | 2025-07-05 00:00:00  | 0 days 02:00:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Japan         |         3270 | 2025-07-04 00:00:00  | 0 days 01:20:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Japan         |         3270 | 2025-07-04 00:00:00  | 0 days 01:20:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Japan         |         3270 | 2025-07-05 00:00:00  | 0 days 01:35:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Japan         |         3270 | 2025-07-05 00:00:00  | 0 days 01:55:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Japan         |         3270 | 2025-07-06 00:00:00  | 0 days 03:10:00 | LIVE           | NOT LIVE               |\n",
      "| -                                       | Belgium       |          nan | 2025-07-05 00:00:00  | 0 days 01:55:00 | LIVE           | NOT LIVE               |\n",
      "| FORMULE 1 GRAND PRIX DE GRANDE BRETAGNE | France        |         1040 | 2025-07-05 00:00:00  | 0 days 02:00:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Brazil        |         3174 | 2025-07-04 00:00:00  | 0 days 00:55:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Brazil        |         3174 | 2025-07-04 00:00:00  | 0 days 00:55:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Brazil        |         3174 | 2025-07-05 00:00:00  | 0 days 00:55:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Brazil        |         3174 | 2025-07-05 00:00:00  | 0 days 01:15:00 | LIVE           | NOT LIVE               |\n",
      "| nan                                     | Brazil        |         2725 | 2025-07-06 00:00:00  | 0 days 01:38:00 | LIVE           | NOT LIVE               |\n",
      "\n",
      "--- Analysis of Failure Modes ---\n",
      "To analyze the cause of these 54 FN's, check their 'Start Datetime UTC' against the official schedule.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "# Assuming df and the required classification columns have been generated by the previous code steps:\n",
    "\n",
    "# 1. Define the True LIVE ground truth based on harmonization\n",
    "df['Ground Truth'] = df['Type of program'].apply(lambda category: \n",
    "    'LIVE' if str(category).strip().lower() in ['live', 'live broadcast', 'race live', 'quali live'] else 'NOT LIVE'\n",
    ")\n",
    "\n",
    "# 2. Define the Model Classification (as generated in the previous step's logic)\n",
    "# This uses the 'Model Classification' column created by the classify_live_only function\n",
    "# (If your 'Model Classification' column is already correct, this line is redundant but safe)\n",
    "df['Model Classification'] = df['Model Classification'].apply(lambda x: \n",
    "    'LIVE' if str(x).startswith('LIVE') else 'NOT LIVE'\n",
    ")\n",
    "\n",
    "# 3. Filter for False Negatives (FN): Ground Truth is LIVE, but Model is NOT LIVE\n",
    "df_false_negatives = df[\n",
    "    (df['Ground Truth'] == 'LIVE') & \n",
    "    (df['Model Classification'] == 'NOT LIVE')\n",
    "].copy() # .copy() prevents SettingWithCopyWarning\n",
    "\n",
    "# 4. Display the results\n",
    "fn_count = len(df_false_negatives)\n",
    "print(f\"âœ… Extracted {fn_count} False Negative rows (Missed LIVE events).\")\n",
    "\n",
    "# Display a subset of columns relevant for debugging the time window issue\n",
    "display_cols = [\n",
    "    'Program Title', \n",
    "    'Market',\n",
    "    'Channel ID',\n",
    "    'Start Datetime UTC', \n",
    "    'Duration_td',\n",
    "    'Ground Truth', \n",
    "    'Model Classification'\n",
    "]\n",
    "\n",
    "print(\"\\n--- False Negatives (Missed LIVE Events) DataFrame ---\")\n",
    "# Use the display() function if in a notebook environment\n",
    "print(df_false_negatives[display_cols].head(54).to_markdown(index=False))\n",
    "\n",
    "# --- Recommended Next Step: Analyze the failure mode ---\n",
    "print(\"\\n--- Analysis of Failure Modes ---\")\n",
    "\n",
    "# To understand why they were missed, we check the program's UTC start time \n",
    "# relative to the official schedule times (live_events_dt).\n",
    "\n",
    "# Note: The actual analysis requires the live_events_dt list from the previous step \n",
    "# to calculate the offset for each row. \n",
    "print(\"To analyze the cause of these 54 FN's, check their 'Start Datetime UTC' against the official schedule.\")\n",
    "\n",
    "# To improve the model, you would extend the LIVE_WINDOW_BEFORE or LIVE_THRESHOLD_AFTER \n",
    "# slightly based on the earliest/latest outliers in this subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350876c7-2eda-4545-b081-fd56da507ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e7866e5-8efb-4b6a-8962-ec135b11fdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DataFrame loaded successfully from Excel.\n",
      "âœ… Model Classification (LIVE, NOT LIVE, SUSPECT) complete.\n",
      "\n",
      "==================================================\n",
      "âŒ FALSE NEGATIVES (MISSED LIVE EVENTS) ANALYSIS\n",
      "==================================================\n",
      "Total False Negative (Missed LIVE) Rows: 54\n",
      "  - Rows flagged as TIME SUSPECT (00:00:00): 48\n",
      "  - Rows missed due to strict time windows: 6\n",
      "\n",
      "--- False Negatives (Missed LIVE Events) DataFrame (54 rows total) ---\n",
      "| Program Title                           | Market        |   Channel ID | Start Datetime UTC   | Duration_td     | Ground Truth   | Model Classification    |\n",
      "|:----------------------------------------|:--------------|-------------:|:---------------------|:----------------|:---------------|:------------------------|\n",
      "| THE F1 SHOW                             | Ireland       |        38443 | 2025-07-05 10:15:38  | 0 days 00:55:40 | LIVE           | NOT LIVE                |\n",
      "| FORMULA 1 -L 2025                       | Mexico        |         2854 | 2025-07-04 11:25:00  | 0 days 00:35:00 | LIVE           | NOT LIVE                |\n",
      "| THE F1 SHOW                             | UK            |        38443 | 2025-07-05 10:15:38  | 0 days 00:55:40 | LIVE           | NOT LIVE                |\n",
      "| -                                       | Vietnam       |         4425 | 2025-07-04 11:20:00  | 0 days 00:30:00 | LIVE           | NOT LIVE                |\n",
      "| nan                                     | Albania       |          nan | 2025-07-05 00:00:00  | 0 days 01:20:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Albania       |          nan | 2025-07-06 00:00:00  | 0 days 02:20:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | China         |          nan | 2025-07-04 00:00:00  | 0 days 01:30:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | China         |          nan | 2025-07-04 00:00:00  | 0 days 01:30:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | China         |          nan | 2025-07-05 00:00:00  | 0 days 01:00:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | China         |          nan | 2025-07-05 00:00:00  | 0 days 01:00:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | China         |          nan | 2025-07-06 00:00:00  | 0 days 02:00:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Estonia       |          nan | 2025-07-04 00:00:00  | 0 days 01:15:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Estonia       |          nan | 2025-07-04 00:00:00  | 0 days 01:15:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Estonia       |          nan | 2025-07-05 00:00:00  | 0 days 01:15:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Estonia       |          nan | 2025-07-05 00:00:00  | 0 days 01:50:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Estonia       |          nan | 2025-07-06 00:00:00  | 0 days 03:15:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Lithuania     |          nan | 2025-07-04 00:00:00  | 0 days 01:15:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Lithuania     |          nan | 2025-07-04 00:00:00  | 0 days 01:15:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Lithuania     |          nan | 2025-07-05 00:00:00  | 0 days 01:15:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Lithuania     |          nan | 2025-07-05 00:00:00  | 0 days 01:50:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Lithuania     |          nan | 2025-07-06 00:00:00  | 0 days 03:15:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Latvia        |          nan | 2025-07-04 00:00:00  | 0 days 01:15:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Latvia        |          nan | 2025-07-04 00:00:00  | 0 days 01:15:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Latvia        |          nan | 2025-07-05 00:00:00  | 0 days 01:15:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Latvia        |          nan | 2025-07-05 00:00:00  | 0 days 01:50:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Latvia        |          nan | 2025-07-06 00:00:00  | 0 days 03:15:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Netherlands   |          nan | 2025-07-04 00:00:00  | 0 days 01:10:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Netherlands   |          nan | 2025-07-04 00:00:00  | 0 days 01:10:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Netherlands   |          nan | 2025-07-04 00:00:00  | 0 days 01:53:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Netherlands   |          nan | 2025-07-04 00:00:00  | 0 days 01:53:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Netherlands   |          nan | 2025-07-05 00:00:00  | 0 days 01:10:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Netherlands   |          nan | 2025-07-05 00:00:00  | 0 days 02:45:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Netherlands   |          nan | 2025-07-06 00:00:00  | 0 days 03:45:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Pan-Carribean |          nan | 2025-07-04 00:00:00  | 0 days 01:00:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Pan-Carribean |          nan | 2025-07-04 00:00:00  | 0 days 01:00:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Pan-Carribean |          nan | 2025-07-05 00:00:00  | 0 days 01:00:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Pan-Carribean |          nan | 2025-07-05 00:00:00  | 0 days 01:30:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Pan-Carribean |          nan | 2025-07-06 00:00:00  | 0 days 02:00:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| FORMULA 1 -L 2025                       | Mexico        |          nan | 2025-07-06 00:00:00  | 0 days 02:00:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Australia     |         6095 | 2025-07-06 15:45:21  | 0 days 00:14:38 | LIVE           | NOT LIVE                |\n",
      "| nan                                     | Australia     |         6095 | 2025-07-07 16:00:00  | 0 days 00:22:53 | LIVE           | NOT LIVE                |\n",
      "| nan                                     | Myanmar       |          nan | 2025-07-05 00:00:00  | 0 days 02:00:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Japan         |         3270 | 2025-07-04 00:00:00  | 0 days 01:20:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Japan         |         3270 | 2025-07-04 00:00:00  | 0 days 01:20:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Japan         |         3270 | 2025-07-05 00:00:00  | 0 days 01:35:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Japan         |         3270 | 2025-07-05 00:00:00  | 0 days 01:55:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Japan         |         3270 | 2025-07-06 00:00:00  | 0 days 03:10:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| -                                       | Belgium       |          nan | 2025-07-05 00:00:00  | 0 days 01:55:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| FORMULE 1 GRAND PRIX DE GRANDE BRETAGNE | France        |         1040 | 2025-07-05 00:00:00  | 0 days 02:00:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Brazil        |         3174 | 2025-07-04 00:00:00  | 0 days 00:55:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Brazil        |         3174 | 2025-07-04 00:00:00  | 0 days 00:55:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Brazil        |         3174 | 2025-07-05 00:00:00  | 0 days 00:55:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Brazil        |         3174 | 2025-07-05 00:00:00  | 0 days 01:15:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "| nan                                     | Brazil        |         2725 | 2025-07-06 00:00:00  | 0 days 01:38:00 | LIVE           | TIME SUSPECT (00:00:00) |\n",
      "\n",
      "--- Actionable Insight ---\n",
      "The model now isolates 48 false negatives that are highly likely due to bad data (00:00:00 time input).\n",
      "Focus your next improvement step on relaxing the time windows to capture the remaining 6 'NOT LIVE' rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from datetime import datetime, time\n",
    "\n",
    "# --- 0. Data Loading ---\n",
    "# NOTE: This section relies on your successful loading of the Excel file.\n",
    "try:\n",
    "    df = pd.read_excel(\n",
    "        \"data/WF 3 F1-R12 - Great Britain.xlsx\",\n",
    "        sheet_name=\"Worksheet\",\n",
    "        header=5 \n",
    "    )\n",
    "    print(\"âœ… DataFrame loaded successfully from Excel.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ ERROR: File not found. Using dummy structure for logic demonstration.\")\n",
    "    # Dummy data tailored to test the 00:00:00 boundary condition\n",
    "    df = pd.DataFrame({\n",
    "        'Program Title': ['P3 LIVE', 'P3 LIVE', 'Quali Replay', 'Pre-Show', 'P3 LIVE (Suspect)'],\n",
    "        'Date (UTC/GMT)': pd.to_datetime(['2025-07-05', '2025-07-05', '2025-07-05', '2025-07-05', '2025-07-05']),\n",
    "        'Start (UTC)': [time(10, 30, 0), time(10, 45, 0), time(18, 0, 0), time(9, 30, 0), time(0, 0, 0)], # 00:00:00 here\n",
    "        'Duration': ['01:30:00', '01:30:00', '02:00:00', '01:00:00', '01:20:00'],\n",
    "        'Type of program': ['Live', 'Live', 'Repeat', 'Pre-Show', 'Live'], # Ground Truth (P3 Live at 00:00:00 is FN)\n",
    "        'Market': ['GB', 'FR', 'DE', 'GB', 'Albania'],\n",
    "        'Channel ID': [101.0, 102.0, 101.0, 101.0, np.nan]\n",
    "    })\n",
    "    \n",
    "if df.empty:\n",
    "    print(\"Cannot proceed with an empty DataFrame.\")\n",
    "    exit()\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 1. Data Preparation and Schedule Definition ðŸ—“ï¸\n",
    "\n",
    "live_schedule = [\n",
    "    ('Practice 1', '4-Jul-2025', '11:30:00'),\n",
    "    ('Practice 2', '4-Jul-2025', '15:00:00'),\n",
    "    ('Practice 3', '5-Jul-2025', '10:30:00'), # Official P3 Start\n",
    "    ('Qualifying', '5-Jul-2025', '14:00:00'),\n",
    "    ('GRAND PRIX', '6-Jul-2025', '14:00:00')\n",
    "]\n",
    "\n",
    "live_events_dt = [pd.to_datetime(f\"{date} {time}\", format='%d-%b-%Y %H:%M:%S') for title, date, time in live_schedule]\n",
    "\n",
    "# Re-run essential data cleaning columns\n",
    "def extract_time_string(time_value):\n",
    "    if pd.isna(time_value): return '00:00:00'\n",
    "    if isinstance(time_value, time): return time_value.strftime('%H:%M:%S')\n",
    "    if isinstance(time_value, datetime): return time_value.time().strftime('%H:%M:%S')\n",
    "    try: return pd.to_datetime(str(time_value)).time().strftime('%H:%M:%S')\n",
    "    except: return '00:00:00'\n",
    "\n",
    "def parse_duration(duration_str):\n",
    "    if pd.isna(duration_str) or str(duration_str).strip() == '': return pd.Timedelta(seconds=0)\n",
    "    try:\n",
    "        h, m, s = map(int, str(duration_str).split(':'))\n",
    "        return pd.Timedelta(hours=h, minutes=m, seconds=s)\n",
    "    except: return pd.Timedelta(seconds=0)\n",
    "\n",
    "df['Date (UTC/GMT)'] = pd.to_datetime(df['Date (UTC/GMT)'], errors='coerce')\n",
    "df['Clean_Time_UTC_Str'] = df['Start (UTC)'].apply(extract_time_string)\n",
    "df['Start Datetime UTC'] = pd.to_datetime(df['Date (UTC/GMT)'].dt.strftime('%Y-%m-%d') + ' ' + df['Clean_Time_UTC_Str'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "df['Duration_td'] = df['Duration'].apply(parse_duration)\n",
    "df = df.replace({pd.NaT: np.nan}) \n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 2. Optimized LIVE Classification Logic with Zero-Time Flag ðŸŽ¯\n",
    "\n",
    "# OPTIMIZED LIVE PARAMETERS\n",
    "MIN_LIVE_PRACTICE_DURATION = pd.Timedelta(minutes=60)\n",
    "LIVE_WINDOW_BEFORE = pd.Timedelta(hours=1)\n",
    "LIVE_THRESHOLD_AFTER = pd.Timedelta(minutes=150)\n",
    "\n",
    "# Define the zero time as a datetime object for comparison\n",
    "SUSPECT_TIME = pd.to_datetime('1900-01-01 00:00:00').time()\n",
    "\n",
    "\n",
    "def classify_live_only(row):\n",
    "    start_dt_utc = row['Start Datetime UTC']\n",
    "    duration = row['Duration_td']\n",
    "\n",
    "    if pd.isna(start_dt_utc) or pd.isna(duration) or duration == pd.Timedelta(seconds=0):\n",
    "        return 'NOT LIVE'\n",
    "    \n",
    "    # ðŸ”‘ NEW LOGIC: FLAG SUSPECT TIMES\n",
    "    # Check if the time component of the UTC start is exactly 00:00:00\n",
    "    if start_dt_utc.time() == SUSPECT_TIME:\n",
    "        return 'TIME SUSPECT (00:00:00)'\n",
    "\n",
    "    # --- LIVE Check (Only runs if time is NOT suspect) ---\n",
    "    for live_dt in live_events_dt:\n",
    "        if (start_dt_utc >= live_dt - LIVE_WINDOW_BEFORE) and \\\n",
    "           (start_dt_utc <= live_dt + LIVE_THRESHOLD_AFTER):\n",
    "            \n",
    "            if duration >= MIN_LIVE_PRACTICE_DURATION:\n",
    "                return 'LIVE'\n",
    "    \n",
    "    return 'NOT LIVE'\n",
    "\n",
    "df['Model Classification'] = df.apply(classify_live_only, axis=1)\n",
    "print(\"âœ… Model Classification (LIVE, NOT LIVE, SUSPECT) complete.\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 3. Harmonize and Validate ðŸ“ˆ\n",
    "\n",
    "# Normalize the original 'Type of program' column to a simple LIVE / NOT LIVE\n",
    "def harmonize_ground_truth_live_only(category):\n",
    "    category = str(category).strip().lower()\n",
    "    if category in ['live', 'live broadcast', 'race live', 'quali live']:\n",
    "        return 'LIVE'\n",
    "    return 'NOT LIVE'\n",
    "\n",
    "df['Ground Truth'] = df['Type of program'].apply(harmonize_ground_truth_live_only)\n",
    "\n",
    "# Calculate Agreement\n",
    "# Agreement is TRUE if: (Model is LIVE and Truth is LIVE) OR (Model is NOT LIVE and Truth is NOT LIVE)\n",
    "# The SUSPECT category must always be considered an 'Incorrect' classification\n",
    "df['Agreement'] = np.where(\n",
    "    (df['Model Classification'] == df['Ground Truth']), \n",
    "    'Correct', \n",
    "    'Incorrect'\n",
    ")\n",
    "# Force SUSPECT and NOT LIVE predictions on a LIVE ground truth to be Incorrect/FN\n",
    "df.loc[\n",
    "    (df['Ground Truth'] == 'LIVE') & (df['Model Classification'] == 'TIME SUSPECT (00:00:00)'), \n",
    "    'Agreement'\n",
    "] = 'Incorrect'\n",
    "\n",
    "# 4. Filter for False Negatives (FN): Ground Truth is LIVE, but Model is NOT LIVE or SUSPECT\n",
    "df_false_negatives = df[\n",
    "    (df['Ground Truth'] == 'LIVE') & \n",
    "    (df['Model Classification'] != 'LIVE')\n",
    "].copy()\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 4. Output: False Negatives\n",
    "\n",
    "fn_count = len(df_false_negatives)\n",
    "suspect_fn_count = (df_false_negatives['Model Classification'] == 'TIME SUSPECT (00:00:00)').sum()\n",
    "pure_fn_count = (df_false_negatives['Model Classification'] == 'NOT LIVE').sum()\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"âŒ FALSE NEGATIVES (MISSED LIVE EVENTS) ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Total False Negative (Missed LIVE) Rows: {fn_count}\")\n",
    "print(f\"  - Rows flagged as TIME SUSPECT (00:00:00): {suspect_fn_count}\")\n",
    "print(f\"  - Rows missed due to strict time windows: {pure_fn_count}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- False Negatives (Missed LIVE Events) DataFrame (54 rows total) ---\")\n",
    "display_cols = [\n",
    "    'Program Title', \n",
    "    'Market',\n",
    "    'Channel ID',\n",
    "    'Start Datetime UTC', \n",
    "    'Duration_td',\n",
    "    'Ground Truth', \n",
    "    'Model Classification'\n",
    "]\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df_false_negatives[display_cols].to_markdown(index=False))\n",
    "\n",
    "# --- Recommended Next Step: Action ---\n",
    "print(\"\\n--- Actionable Insight ---\")\n",
    "print(f\"The model now isolates {suspect_fn_count} false negatives that are highly likely due to bad data (00:00:00 time input).\")\n",
    "print(\"Focus your next improvement step on relaxing the time windows to capture the remaining {} 'NOT LIVE' rows.\".format(pure_fn_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098324ed-6f26-4845-ae09-cd7c3806fd1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7898aa6e-1567-44d9-af31-18765cdc885b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7faf553-cfda-4dfd-b669-01366332a01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DataFrame loaded successfully from Excel.\n",
      "âœ… Model Classification (LIVE, NOT LIVE, SUSPECT) complete.\n",
      "\n",
      "==================================================\n",
      "ðŸŽ¯ LIVE CLASSIFICATION PERFORMANCE (WITH SUSPECT FLAG)\n",
      "==================================================\n",
      "Total Programs Analyzed: 2994\n",
      "Total True LIVE Events:  471\n",
      "Total NOT LIVE Events:   2523\n",
      "\n",
      "| Metric | Value |\n",
      "|:---|:---|\n",
      "| **Overall Accuracy** | 108.68% |\n",
      "| **Precision (Model)**| 80.19% |\n",
      "| **Recall (Model)** | 88.54% |\n",
      "| **False Positives (FP)** | 103 |\n",
      "| **False Negatives (Pure Miss)** | 6 |\n",
      "| **False Negatives (Suspect Data)** | 48 |\n",
      "\n",
      "| Confusion Matrix |\n",
      "| Ground Truth   |   LIVE |   NOT LIVE |   NOT LIVE (Suspect) |\n",
      "|:---------------|-------:|-----------:|---------------------:|\n",
      "| LIVE           |    417 |          6 |                   48 |\n",
      "| NOT LIVE       |    103 |       2348 |                   72 |\n",
      "\n",
      "| Examples of Incorrect Classification |\n",
      "| Program Title   | Start Datetime UTC   | Duration_td     | Ground Truth   | Model Classification   | Agreement   |\n",
      "|:----------------|:---------------------|:----------------|:---------------|:-----------------------|:------------|\n",
      "| -               | 2025-07-05 11:30:00  | 0 days 02:00:00 | NOT LIVE       | LIVE                   | Incorrect   |\n",
      "| -               | 2025-07-05 13:30:00  | 0 days 03:00:00 | NOT LIVE       | LIVE                   | Incorrect   |\n",
      "| -               | 2025-07-05 16:30:00  | 0 days 03:00:00 | NOT LIVE       | LIVE                   | Incorrect   |\n",
      "| -               | 2025-07-06 14:00:00  | 0 days 02:00:00 | NOT LIVE       | LIVE                   | Incorrect   |\n",
      "| -               | 2025-07-04 16:15:00  | 0 days 01:00:00 | NOT LIVE       | LIVE                   | Incorrect   |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from datetime import datetime, time\n",
    "\n",
    "# --- 0. Data Loading ---\n",
    "# NOTE: This section relies on your successful loading of the Excel file.\n",
    "try:\n",
    "    df = pd.read_excel(\n",
    "        \"data/WF 3 F1-R12 - Great Britain.xlsx\",\n",
    "        sheet_name=\"Worksheet\",\n",
    "        header=5 \n",
    "    )\n",
    "    print(\"âœ… DataFrame loaded successfully from Excel.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ ERROR: File not found. Using dummy structure for logic demonstration.\")\n",
    "    # Dummy data tailored to test the LIVE boundary conditions and include a suspect row\n",
    "    df = pd.DataFrame({\n",
    "        'Program Title': ['P1 Live', 'P1 Live', 'Post-Race Analysis', 'P1 Delayed', 'Race Live', 'Race Pre-Show', 'Race Replay', 'News', 'P3 Live (Suspect)'],\n",
    "        'Date (UTC/GMT)': pd.to_datetime(['2025-07-04', '2025-07-04', '2025-07-04', '2025-07-04', '2025-07-06', '2025-07-06', '2025-07-06', '2025-07-06', '2025-07-05']),\n",
    "        # The 00:00:00 time is added here for the Suspect row test\n",
    "        'Start (UTC)': [time(11, 30, 0), time(11, 45, 0), time(14, 0, 0), time(18, 0, 0), time(14, 0, 0), time(13, 0, 0), time(20, 0, 0), time(18, 0, 0), time(0, 0, 0)], \n",
    "        'Duration': ['01:30:00', '01:30:00', '01:30:00', '01:30:00', '02:00:00', '01:00:00', '02:00:00', '00:30:00', '01:20:00'],\n",
    "        'Type of program': ['Live', 'Live', 'Pre-Show', 'Repeat', 'Live', 'Pre-Show', 'Repeat', 'News', 'Live'], # Ground Truth\n",
    "    })\n",
    "    \n",
    "if df.empty:\n",
    "    print(\"Cannot proceed with an empty DataFrame.\")\n",
    "    exit()\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 1. Data Preparation and Schedule Definition ðŸ—“ï¸\n",
    "\n",
    "live_schedule = [\n",
    "    ('Practice 1', '4-Jul-2025', '11:30:00'),\n",
    "    ('Practice 2', '4-Jul-2025', '15:00:00'),\n",
    "    ('Practice 3', '5-Jul-2025', '10:30:00'),\n",
    "    ('Qualifying', '5-Jul-2025', '14:00:00'),\n",
    "    ('GRAND PRIX', '6-Jul-2025', '14:00:00')\n",
    "]\n",
    "\n",
    "live_events_dt = [pd.to_datetime(f\"{date} {time}\", format='%d-%b-%Y %H:%M:%S') for title, date, time in live_schedule]\n",
    "\n",
    "# Re-run essential data cleaning columns\n",
    "def extract_time_string(time_value):\n",
    "    if pd.isna(time_value): return '00:00:00'\n",
    "    if isinstance(time_value, time): return time_value.strftime('%H:%M:%S')\n",
    "    if isinstance(time_value, datetime): return time_value.time().strftime('%H:%M:%S')\n",
    "    try: return pd.to_datetime(str(time_value)).time().strftime('%H:%M:%S')\n",
    "    except: return '00:00:00'\n",
    "\n",
    "def parse_duration(duration_str):\n",
    "    if pd.isna(duration_str) or str(duration_str).strip() == '': return pd.Timedelta(seconds=0)\n",
    "    try:\n",
    "        h, m, s = map(int, str(duration_str).split(':'))\n",
    "        return pd.Timedelta(hours=h, minutes=m, seconds=s)\n",
    "    except: return pd.Timedelta(seconds=0)\n",
    "\n",
    "df['Date (UTC/GMT)'] = pd.to_datetime(df['Date (UTC/GMT)'], errors='coerce')\n",
    "df['Clean_Time_UTC_Str'] = df['Start (UTC)'].apply(extract_time_string)\n",
    "df['Start Datetime UTC'] = pd.to_datetime(df['Date (UTC/GMT)'].dt.strftime('%Y-%m-%d') + ' ' + df['Clean_Time_UTC_Str'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "df['Duration_td'] = df['Duration'].apply(parse_duration)\n",
    "df = df.replace({pd.NaT: np.nan}) \n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 2. Optimized LIVE Classification Logic with Suspect Flag ðŸŽ¯\n",
    "\n",
    "# OPTIMIZED LIVE PARAMETERS\n",
    "MIN_LIVE_PRACTICE_DURATION = pd.Timedelta(minutes=60)\n",
    "LIVE_WINDOW_BEFORE = pd.Timedelta(hours=1)\n",
    "LIVE_THRESHOLD_AFTER = pd.Timedelta(minutes=150)\n",
    "# Define the zero time object for the suspect check\n",
    "SUSPECT_TIME = pd.to_datetime('1900-01-01 00:00:00').time()\n",
    "\n",
    "\n",
    "def classify_live_only(row):\n",
    "    start_dt_utc = row['Start Datetime UTC']\n",
    "    duration = row['Duration_td']\n",
    "\n",
    "    if pd.isna(start_dt_utc) or pd.isna(duration) or duration == pd.Timedelta(seconds=0):\n",
    "        return 'NOT LIVE'\n",
    "    \n",
    "    # ðŸ”‘ NEW LOGIC: FLAG SUSPECT TIMES (00:00:00 UTC)\n",
    "    if start_dt_utc.time() == SUSPECT_TIME:\n",
    "        return 'TIME SUSPECT'\n",
    "\n",
    "    # Check against ALL scheduled live times\n",
    "    for live_dt in live_events_dt:\n",
    "        # Check if program starts within the STRICT live window (1hr before, 2.5hrs after)\n",
    "        if (start_dt_utc >= live_dt - LIVE_WINDOW_BEFORE) and \\\n",
    "           (start_dt_utc <= live_dt + LIVE_THRESHOLD_AFTER):\n",
    "            \n",
    "            # Check for minimum required duration for a session\n",
    "            if duration >= MIN_LIVE_PRACTICE_DURATION:\n",
    "                return 'LIVE'\n",
    "    \n",
    "    return 'NOT LIVE'\n",
    "\n",
    "df['Model Classification'] = df.apply(classify_live_only, axis=1)\n",
    "print(\"âœ… Model Classification (LIVE, NOT LIVE, SUSPECT) complete.\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 3. Harmonize and Validate ðŸ“ˆ\n",
    "\n",
    "# Normalize the original 'Type of program' column to a simple LIVE / NOT LIVE\n",
    "def harmonize_ground_truth_live_only(category):\n",
    "    category = str(category).strip().lower()\n",
    "    if category in ['live', 'live broadcast', 'race live', 'quali live']:\n",
    "        return 'LIVE'\n",
    "    return 'NOT LIVE'\n",
    "\n",
    "df['Ground Truth'] = df['Type of program'].apply(harmonize_ground_truth_live_only)\n",
    "\n",
    "# Calculate Agreement\n",
    "# Agreement is TRUE if: (Model is LIVE and Truth is LIVE) OR (Model is NOT LIVE and Truth is NOT LIVE)\n",
    "# Agreement is FALSE if: (Model is SUSPECT) OR (Model/Truth are different)\n",
    "df['Agreement'] = np.where(\n",
    "    (df['Model Classification'] == df['Ground Truth']), \n",
    "    'Correct', \n",
    "    'Incorrect'\n",
    ")\n",
    "# Force SUSPECT to be Incorrect regardless of Ground Truth (as it's a data quality issue)\n",
    "df.loc[\n",
    "    df['Model Classification'] == 'TIME SUSPECT', \n",
    "    'Agreement'\n",
    "] = 'Incorrect (Suspect Time)'\n",
    "\n",
    "\n",
    "# Calculate Metrics for LIVE vs. NOT LIVE performance\n",
    "true_live = (df['Ground Truth'] == 'LIVE').sum()\n",
    "true_not_live = (df['Ground Truth'] == 'NOT LIVE').sum()\n",
    "\n",
    "TP = ((df['Ground Truth'] == 'LIVE') & (df['Model Classification'] == 'LIVE')).sum()       # True Positives\n",
    "FP = ((df['Ground Truth'] == 'NOT LIVE') & (df['Model Classification'] == 'LIVE')).sum()   # False Positives\n",
    "FN_pure = ((df['Ground Truth'] == 'LIVE') & (df['Model Classification'] == 'NOT LIVE')).sum()   # False Negatives (Missed)\n",
    "FN_suspect = ((df['Ground Truth'] == 'LIVE') & (df['Model Classification'] == 'TIME SUSPECT')).sum() # False Negatives (Suspect Data)\n",
    "\n",
    "# Total FN is the sum of pure misses and suspect data misses\n",
    "FN_total = FN_pure + FN_suspect\n",
    "\n",
    "# Safety check for division by zero\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN_total) if (TP + FN_total) > 0 else 0\n",
    "accuracy = (TP + (len(df) - FN_total - FP)) / len(df) # Recalculated accuracy excluding suspect time errors from TN\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 4. Output Summary\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸŽ¯ LIVE CLASSIFICATION PERFORMANCE (WITH SUSPECT FLAG)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Total Programs Analyzed: {len(df)}\")\n",
    "print(f\"Total True LIVE Events:  {true_live}\")\n",
    "print(f\"Total NOT LIVE Events:   {true_not_live}\")\n",
    "\n",
    "print(\"\\n| Metric | Value |\")\n",
    "print(\"|:---|:---|\")\n",
    "print(f\"| **Overall Accuracy** | {accuracy:.2%} |\")\n",
    "print(f\"| **Precision (Model)**| {precision:.2%} |\")\n",
    "print(f\"| **Recall (Model)** | {recall:.2%} |\")\n",
    "print(f\"| **False Positives (FP)** | {FP} |\")\n",
    "print(f\"| **False Negatives (Pure Miss)** | {FN_pure} |\")\n",
    "print(f\"| **False Negatives (Suspect Data)** | {FN_suspect} |\")\n",
    "\n",
    "\n",
    "print(\"\\n| Confusion Matrix |\")\n",
    "# Use only LIVE and NOT LIVE for the main matrix for clarity, treating SUSPECT separately\n",
    "confusion_matrix = pd.crosstab(df['Ground Truth'], df['Model Classification'].replace('TIME SUSPECT', 'NOT LIVE (Suspect)'), margins=False)\n",
    "print(confusion_matrix.to_markdown())\n",
    "\n",
    "print(\"\\n| Examples of Incorrect Classification |\")\n",
    "incorrect_examples = df[df['Agreement'] != 'Correct'].head(5)\n",
    "print(incorrect_examples[['Program Title', 'Start Datetime UTC', 'Duration_td', 'Ground Truth', 'Model Classification', 'Agreement']].to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d8d1283-837c-4126-b7cf-d90809462271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ðŸŽ¯ LIVE CLASSIFICATION PERFORMANCE (CORRECTED METRICS)\n",
      "==================================================\n",
      "Total Programs Analyzed: 2994\n",
      "Total True LIVE Events:  471\n",
      "Total NOT LIVE Events:   2523\n",
      "\n",
      "| Metric | Value |\n",
      "|:---|:---|\n",
      "| **Overall Accuracy** | 92.35% |\n",
      "| **Precision (Model)**| 80.19% |\n",
      "| **Recall (Model)** | 88.54% |\n",
      "| **False Positives (FP)** | 103 |\n",
      "| **False Negatives (Pure Miss)** | 6 |\n",
      "| **False Negatives (Suspect Data)** | 48 |\n",
      "\n",
      "| Confusion Matrix |\n",
      "| Ground Truth   |   LIVE |   NOT LIVE |   NOT LIVE (Suspect) |\n",
      "|:---------------|-------:|-----------:|---------------------:|\n",
      "| LIVE           |    417 |          6 |                   48 |\n",
      "| NOT LIVE       |    103 |       2348 |                   72 |\n",
      "\n",
      "| Examples of Incorrect Classification |\n",
      "| Program Title   | Start Datetime UTC   | Duration_td     | Ground Truth   | Model Classification   | Agreement   |\n",
      "|:----------------|:---------------------|:----------------|:---------------|:-----------------------|:------------|\n",
      "| -               | 2025-07-05 11:30:00  | 0 days 02:00:00 | NOT LIVE       | LIVE                   | Incorrect   |\n",
      "| -               | 2025-07-05 13:30:00  | 0 days 03:00:00 | NOT LIVE       | LIVE                   | Incorrect   |\n",
      "| -               | 2025-07-05 16:30:00  | 0 days 03:00:00 | NOT LIVE       | LIVE                   | Incorrect   |\n",
      "| -               | 2025-07-06 14:00:00  | 0 days 02:00:00 | NOT LIVE       | LIVE                   | Incorrect   |\n",
      "| -               | 2025-07-04 16:15:00  | 0 days 01:00:00 | NOT LIVE       | LIVE                   | Incorrect   |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from datetime import datetime, time\n",
    "\n",
    "# --- 0. Data Loading ---\n",
    "# NOTE: Using the structure from the last successful execution block.\n",
    "try:\n",
    "    df = pd.read_excel(\n",
    "        \"data/WF 3 F1-R12 - Great Britain.xlsx\",\n",
    "        sheet_name=\"Worksheet\",\n",
    "        header=5 \n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    # Dummy data adapted from previous steps for demonstration\n",
    "    df = pd.DataFrame({\n",
    "        'Program Title': ['P1 Live', 'P1 Live', 'Post-Race Analysis', 'P1 Delayed', 'Race Live', 'Race Pre-Show', 'Race Replay', 'News', 'P3 Live (Suspect)'],\n",
    "        'Date (UTC/GMT)': pd.to_datetime(['2025-07-04', '2025-07-04', '2025-07-04', '2025-07-04', '2025-07-06', '2025-07-06', '2025-07-06', '2025-07-06', '2025-07-05']),\n",
    "        'Start (UTC)': [time(11, 30, 0), time(11, 45, 0), time(14, 0, 0), time(18, 0, 0), time(14, 0, 0), time(13, 0, 0), time(20, 0, 0), time(18, 0, 0), time(0, 0, 0)], \n",
    "        'Duration': ['01:30:00', '01:30:00', '01:30:00', '01:30:00', '02:00:00', '01:00:00', '02:00:00', '00:30:00', '01:20:00'],\n",
    "        'Type of program': ['Live', 'Live', 'Pre-Show', 'Repeat', 'Live', 'Pre-Show', 'Repeat', 'News', 'Live'], \n",
    "    })\n",
    "    \n",
    "if df.empty:\n",
    "    print(\"Cannot proceed with an empty DataFrame.\")\n",
    "    exit()\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 1. Data Preparation and Schedule Definition ðŸ—“ï¸\n",
    "\n",
    "live_schedule = [\n",
    "    ('Practice 1', '4-Jul-2025', '11:30:00'),\n",
    "    ('Practice 2', '4-Jul-2025', '15:00:00'),\n",
    "    ('Practice 3', '5-Jul-2025', '10:30:00'),\n",
    "    ('Qualifying', '5-Jul-2025', '14:00:00'),\n",
    "    ('GRAND PRIX', '6-Jul-2025', '14:00:00')\n",
    "]\n",
    "\n",
    "live_events_dt = [pd.to_datetime(f\"{date} {time}\", format='%d-%b-%Y %H:%M:%S') for title, date, time in live_schedule]\n",
    "\n",
    "def extract_time_string(time_value):\n",
    "    if pd.isna(time_value): return '00:00:00'\n",
    "    if isinstance(time_value, time): return time_value.strftime('%H:%M:%S')\n",
    "    if isinstance(time_value, datetime): return time_value.time().strftime('%H:%M:%S')\n",
    "    try: return pd.to_datetime(str(time_value)).time().strftime('%H:%M:%S')\n",
    "    except: return '00:00:00'\n",
    "\n",
    "def parse_duration(duration_str):\n",
    "    if pd.isna(duration_str) or str(duration_str).strip() == '': return pd.Timedelta(seconds=0)\n",
    "    try:\n",
    "        h, m, s = map(int, str(duration_str).split(':'))\n",
    "        return pd.Timedelta(hours=h, minutes=m, seconds=s)\n",
    "    except: return pd.Timedelta(seconds=0)\n",
    "\n",
    "df['Date (UTC/GMT)'] = pd.to_datetime(df['Date (UTC/GMT)'], errors='coerce')\n",
    "df['Clean_Time_UTC_Str'] = df['Start (UTC)'].apply(extract_time_string)\n",
    "df['Start Datetime UTC'] = pd.to_datetime(df['Date (UTC/GMT)'].dt.strftime('%Y-%m-%d') + ' ' + df['Clean_Time_UTC_Str'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "df['Duration_td'] = df['Duration'].apply(parse_duration)\n",
    "df = df.replace({pd.NaT: np.nan}) \n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 2. Optimized LIVE Classification Logic with Suspect Flag ðŸŽ¯\n",
    "\n",
    "MIN_LIVE_PRACTICE_DURATION = pd.Timedelta(minutes=60)\n",
    "LIVE_WINDOW_BEFORE = pd.Timedelta(hours=1)\n",
    "LIVE_THRESHOLD_AFTER = pd.Timedelta(minutes=150)\n",
    "SUSPECT_TIME = pd.to_datetime('1900-01-01 00:00:00').time()\n",
    "\n",
    "\n",
    "def classify_live_only(row):\n",
    "    start_dt_utc = row['Start Datetime UTC']\n",
    "    duration = row['Duration_td']\n",
    "\n",
    "    if pd.isna(start_dt_utc) or pd.isna(duration) or duration == pd.Timedelta(seconds=0):\n",
    "        return 'NOT LIVE'\n",
    "    \n",
    "    if start_dt_utc.time() == SUSPECT_TIME:\n",
    "        return 'TIME SUSPECT'\n",
    "\n",
    "    for live_dt in live_events_dt:\n",
    "        if (start_dt_utc >= live_dt - LIVE_WINDOW_BEFORE) and \\\n",
    "           (start_dt_utc <= live_dt + LIVE_THRESHOLD_AFTER):\n",
    "            \n",
    "            if duration >= MIN_LIVE_PRACTICE_DURATION:\n",
    "                return 'LIVE'\n",
    "    \n",
    "    return 'NOT LIVE'\n",
    "\n",
    "df['Model Classification'] = df.apply(classify_live_only, axis=1)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 3. Harmonize and Validate ðŸ“ˆ\n",
    "\n",
    "def harmonize_ground_truth_live_only(category):\n",
    "    category = str(category).strip().lower()\n",
    "    if category in ['live', 'live broadcast', 'race live', 'quali live']:\n",
    "        return 'LIVE'\n",
    "    return 'NOT LIVE'\n",
    "\n",
    "df['Ground Truth'] = df['Type of program'].apply(harmonize_ground_truth_live_only)\n",
    "\n",
    "# Calculate Core Metrics from the provided Confusion Matrix values:\n",
    "TP = 417\n",
    "FP = 103\n",
    "FN_pure = 6\n",
    "FN_suspect = 48\n",
    "TN_clean = 2348\n",
    "TN_suspect = 72\n",
    "Total = 2994\n",
    "\n",
    "# Corrected Total True LIVE Events (TP + FN_pure + FN_suspect)\n",
    "True_Live = 417 + 6 + 48 # 471\n",
    "# Corrected Total True NOT LIVE Events (FP + TN_clean + TN_suspect)\n",
    "True_Not_Live = 103 + 2348 + 72 # 2523\n",
    "\n",
    "# Total Correct Predictions are TP + TN_clean\n",
    "Total_Correct = TP + TN_clean\n",
    "Total_Incorrect = Total - Total_Correct\n",
    "Total_TP_FP = TP + FP\n",
    "\n",
    "# --- CORRECTED METRICS ---\n",
    "\n",
    "# Precision: Of all predicted LIVE events, how many were actually LIVE?\n",
    "Precision_Corrected = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "\n",
    "# Recall: Of all actual LIVE events, how many were correctly predicted LIVE?\n",
    "Recall_Corrected = TP / True_Live if True_Live > 0 else 0\n",
    "\n",
    "# Overall Accuracy: Correct predictions divided by Total predictions (excluding suspect data from the denominator is complex, \n",
    "# so we use the standard approach and acknowledge the suspect misclassification)\n",
    "Accuracy_Corrected = (TP + TN_clean) / Total\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 4. Output Summary (Corrected)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸŽ¯ LIVE CLASSIFICATION PERFORMANCE (CORRECTED METRICS)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Total Programs Analyzed: {Total}\")\n",
    "print(f\"Total True LIVE Events:  {True_Live}\")\n",
    "print(f\"Total NOT LIVE Events:   {True_Not_Live}\")\n",
    "\n",
    "print(\"\\n| Metric | Value |\")\n",
    "print(\"|:---|:---|\")\n",
    "print(f\"| **Overall Accuracy** | {Accuracy_Corrected:.2%} |\") # Corrected from 108.68%\n",
    "print(f\"| **Precision (Model)**| {Precision_Corrected:.2%} |\")\n",
    "print(f\"| **Recall (Model)** | {Recall_Corrected:.2%} |\")\n",
    "print(f\"| **False Positives (FP)** | {FP} |\")\n",
    "print(f\"| **False Negatives (Pure Miss)** | {FN_pure} |\")\n",
    "print(f\"| **False Negatives (Suspect Data)** | {FN_suspect} |\")\n",
    "\n",
    "print(\"\\n| Confusion Matrix |\")\n",
    "# Re-using provided matrix for accuracy\n",
    "print(\"| Ground Truth   |   LIVE |   NOT LIVE |   NOT LIVE (Suspect) |\")\n",
    "print(\"|:---------------|-------:|-----------:|---------------------:|\")\n",
    "print(\"| LIVE           |    417 |          6 |                   48 |\")\n",
    "print(\"| NOT LIVE       |    103 |       2348 |                   72 |\")\n",
    "\n",
    "print(\"\\n| Examples of Incorrect Classification |\")\n",
    "# Re-using a sample of incorrect rows based on the previous output\n",
    "incorrect_examples_data = [\n",
    "    ('-', '2025-07-05 11:30:00', '0 days 02:00:00', 'NOT LIVE', 'LIVE', 'Incorrect'),\n",
    "    ('-', '2025-07-05 13:30:00', '0 days 03:00:00', 'NOT LIVE', 'LIVE', 'Incorrect'),\n",
    "    ('-', '2025-07-05 16:30:00', '0 days 03:00:00', 'NOT LIVE', 'LIVE', 'Incorrect'),\n",
    "    ('-', '2025-07-06 14:00:00', '0 days 02:00:00', 'NOT LIVE', 'LIVE', 'Incorrect'),\n",
    "    ('-', '2025-07-04 16:15:00', '0 days 01:00:00', 'NOT LIVE', 'LIVE', 'Incorrect')\n",
    "]\n",
    "incorrect_examples_df = pd.DataFrame(incorrect_examples_data, columns=['Program Title', 'Start Datetime UTC', 'Duration_td', 'Ground Truth', 'Model Classification', 'Agreement'])\n",
    "print(incorrect_examples_df.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb43f4c7-e523-4f16-b0e1-aa129c009c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DataFrame loaded successfully from Excel.\n",
      "\n",
      "==================================================\n",
      "ðŸŽ¯ LIVE CLASSIFICATION PERFORMANCE (PRECISION OPTIMIZED)\n",
      "==================================================\n",
      "Total Programs Analyzed: 2994\n",
      "Total True LIVE Events:  471\n",
      "Total NOT LIVE Events:   2523\n",
      "\n",
      "| Metric | Value |\n",
      "|:---|:---|\n",
      "| **Overall Accuracy** | 93.19% |\n",
      "| **Precision (Model)**| 84.38% |\n",
      "| **Recall (Model)** | 88.32% |\n",
      "| **False Positives (FP)** | 77 |\n",
      "| **False Negatives (Pure Miss)** | 7 |\n",
      "| **False Negatives (Suspect Data)** | 48 |\n",
      "\n",
      "| Confusion Matrix |\n",
      "| Ground Truth   |   LIVE |   NOT LIVE |   TIME SUSPECT |\n",
      "|:---------------|-------:|-----------:|---------------:|\n",
      "| LIVE           |    416 |          7 |             48 |\n",
      "| NOT LIVE       |     77 |       2374 |             72 |\n",
      "\n",
      "| Examples of Incorrect Classification |\n",
      "| Program Title   | Start Datetime UTC   | Duration_td     | Ground Truth   | Model Classification   |\n",
      "|:----------------|:---------------------|:----------------|:---------------|:-----------------------|\n",
      "| -               | 2025-07-05 11:30:00  | 0 days 02:00:00 | NOT LIVE       | LIVE                   |\n",
      "| -               | 2025-07-05 13:30:00  | 0 days 03:00:00 | NOT LIVE       | LIVE                   |\n",
      "| -               | 2025-07-06 14:00:00  | 0 days 02:00:00 | NOT LIVE       | LIVE                   |\n",
      "| -               | 2025-07-04 16:15:00  | 0 days 01:00:00 | NOT LIVE       | LIVE                   |\n",
      "| -               | 2025-07-06 16:00:00  | 0 days 01:00:00 | NOT LIVE       | LIVE                   |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from datetime import datetime, time\n",
    "\n",
    "# --- 0. Data Loading ---\n",
    "# NOTE: This section relies on your successful loading of the Excel file.\n",
    "try:\n",
    "    df = pd.read_excel(\n",
    "        \"data/WF 3 F1-R12 - Great Britain.xlsx\",\n",
    "        sheet_name=\"Worksheet\",\n",
    "        header=5 \n",
    "    )\n",
    "    print(\"âœ… DataFrame loaded successfully from Excel.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ ERROR: File not found. Using dummy structure for logic demonstration.\")\n",
    "    # Dummy data adapted from previous steps for demonstration\n",
    "    df = pd.DataFrame({\n",
    "        'Program Title': ['P1 Live', 'P1 Live', 'Post-Race Analysis', 'P1 Delayed', 'Race Live', 'Race Pre-Show', 'Race Replay', 'News', 'P3 Live (Suspect)'],\n",
    "        'Date (UTC/GMT)': pd.to_datetime(['2025-07-04', '2025-07-04', '2025-07-04', '2025-07-04', '2025-07-06', '2025-07-06', '2025-07-06', '2025-07-06', '2025-07-05']),\n",
    "        'Start (UTC)': [time(11, 30, 0), time(11, 45, 0), time(14, 0, 0), time(18, 0, 0), time(14, 0, 0), time(13, 0, 0), time(20, 0, 0), time(18, 0, 0), time(0, 0, 0)], \n",
    "        'Duration': ['01:30:00', '01:30:00', '01:30:00', '01:30:00', '02:00:00', '01:00:00', '02:00:00', '00:30:00', '01:20:00'],\n",
    "        'Type of program': ['Live', 'Live', 'Pre-Show', 'Repeat', 'Live', 'Pre-Show', 'Repeat', 'News', 'Live'], \n",
    "    })\n",
    "    \n",
    "if df.empty:\n",
    "    print(\"Cannot proceed with an empty DataFrame.\")\n",
    "    exit()\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 1. Data Preparation and Schedule Definition ðŸ—“ï¸\n",
    "\n",
    "live_schedule = [\n",
    "    ('Practice 1', '4-Jul-2025', '11:30:00'),\n",
    "    ('Practice 2', '4-Jul-2025', '15:00:00'),\n",
    "    ('Practice 3', '5-Jul-2025', '10:30:00'),\n",
    "    ('Qualifying', '5-Jul-2025', '14:00:00'),\n",
    "    ('GRAND PRIX', '6-Jul-2025', '14:00:00')\n",
    "]\n",
    "\n",
    "live_events_dt = [pd.to_datetime(f\"{date} {time}\", format='%d-%b-%Y %H:%M:%S') for title, date, time in live_schedule]\n",
    "\n",
    "def extract_time_string(time_value):\n",
    "    if pd.isna(time_value): return '00:00:00'\n",
    "    if isinstance(time_value, time): return time_value.strftime('%H:%M:%S')\n",
    "    if isinstance(time_value, datetime): return time_value.time().strftime('%H:%M:%S')\n",
    "    try: return pd.to_datetime(str(time_value)).time().strftime('%H:%M:%S')\n",
    "    except: return '00:00:00'\n",
    "\n",
    "def parse_duration(duration_str):\n",
    "    if pd.isna(duration_str) or str(duration_str).strip() == '': return pd.Timedelta(seconds=0)\n",
    "    try:\n",
    "        h, m, s = map(int, str(duration_str).split(':'))\n",
    "        return pd.Timedelta(hours=h, minutes=m, seconds=s)\n",
    "    except: return pd.Timedelta(seconds=0)\n",
    "\n",
    "df['Date (UTC/GMT)'] = pd.to_datetime(df['Date (UTC/GMT)'], errors='coerce')\n",
    "df['Clean_Time_UTC_Str'] = df['Start (UTC)'].apply(extract_time_string)\n",
    "df['Start Datetime UTC'] = pd.to_datetime(df['Date (UTC/GMT)'].dt.strftime('%Y-%m-%d') + ' ' + df['Clean_Time_UTC_Str'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "df['Duration_td'] = df['Duration'].apply(parse_duration)\n",
    "df = df.replace({pd.NaT: np.nan}) \n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 2. Optimized LIVE Classification Logic with Suspect Flag ðŸŽ¯\n",
    "\n",
    "MIN_LIVE_PRACTICE_DURATION = pd.Timedelta(minutes=60)\n",
    "LIVE_WINDOW_BEFORE = pd.Timedelta(hours=1)\n",
    "# ðŸ”‘ OPTIMIZATION: Reduced post-event buffer from 150 mins to 120 mins (2 hours)\n",
    "LIVE_THRESHOLD_AFTER = pd.Timedelta(minutes=120) \n",
    "SUSPECT_TIME = pd.to_datetime('1900-01-01 00:00:00').time()\n",
    "\n",
    "\n",
    "def classify_live_only(row):\n",
    "    start_dt_utc = row['Start Datetime UTC']\n",
    "    duration = row['Duration_td']\n",
    "\n",
    "    if pd.isna(start_dt_utc) or pd.isna(duration) or duration == pd.Timedelta(seconds=0):\n",
    "        return 'NOT LIVE'\n",
    "    \n",
    "    if start_dt_utc.time() == SUSPECT_TIME:\n",
    "        return 'TIME SUSPECT'\n",
    "\n",
    "    for live_dt in live_events_dt:\n",
    "        if (start_dt_utc >= live_dt - LIVE_WINDOW_BEFORE) and \\\n",
    "           (start_dt_utc <= live_dt + LIVE_THRESHOLD_AFTER):\n",
    "            \n",
    "            if duration >= MIN_LIVE_PRACTICE_DURATION:\n",
    "                return 'LIVE'\n",
    "    \n",
    "    return 'NOT LIVE'\n",
    "\n",
    "df['Model Classification'] = df.apply(classify_live_only, axis=1)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 3. Harmonize and Validate ðŸ“ˆ\n",
    "\n",
    "def harmonize_ground_truth_live_only(category):\n",
    "    category = str(category).strip().lower()\n",
    "    if category in ['live', 'live broadcast', 'race live', 'quali live']:\n",
    "        return 'LIVE'\n",
    "    return 'NOT LIVE'\n",
    "\n",
    "df['Ground Truth'] = df['Type of program'].apply(harmonize_ground_truth_live_only)\n",
    "\n",
    "# Calculate Core Metrics from the provided Confusion Matrix values\n",
    "# NOTE: The actual TP/FP/FN counts will change with the new logic, but we must use \n",
    "# the calculated counts from the DataFrame for the final output. \n",
    "\n",
    "# Re-calculate TP, FP, FN, TN based on the new 'Model Classification'\n",
    "TP = ((df['Ground Truth'] == 'LIVE') & (df['Model Classification'] == 'LIVE')).sum()\n",
    "FP = ((df['Ground Truth'] == 'NOT LIVE') & (df['Model Classification'] == 'LIVE')).sum()\n",
    "FN_pure = ((df['Ground Truth'] == 'LIVE') & (df['Model Classification'] == 'NOT LIVE')).sum()\n",
    "FN_suspect = ((df['Ground Truth'] == 'LIVE') & (df['Model Classification'] == 'TIME SUSPECT')).sum()\n",
    "TN_clean = ((df['Ground Truth'] == 'NOT LIVE') & (df['Model Classification'] == 'NOT LIVE')).sum()\n",
    "TN_suspect = ((df['Ground Truth'] == 'NOT LIVE') & (df['Model Classification'] == 'TIME SUSPECT')).sum()\n",
    "\n",
    "# Totals\n",
    "Total = len(df)\n",
    "True_Live = (df['Ground Truth'] == 'LIVE').sum()\n",
    "True_Not_Live = (df['Ground Truth'] == 'NOT LIVE').sum()\n",
    "FN_total = FN_pure + FN_suspect\n",
    "\n",
    "# --- CORRECTED METRICS ---\n",
    "\n",
    "Precision_Corrected = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "Recall_Corrected = TP / True_Live if True_Live > 0 else 0\n",
    "Accuracy_Corrected = (TP + TN_clean) / Total # Standard definition for accuracy\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 4. Output Summary (Corrected)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸŽ¯ LIVE CLASSIFICATION PERFORMANCE (PRECISION OPTIMIZED)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Total Programs Analyzed: {Total}\")\n",
    "print(f\"Total True LIVE Events:  {True_Live}\")\n",
    "print(f\"Total NOT LIVE Events:   {True_Not_Live}\")\n",
    "\n",
    "print(\"\\n| Metric | Value |\")\n",
    "print(\"|:---|:---|\")\n",
    "print(f\"| **Overall Accuracy** | {Accuracy_Corrected:.2%} |\") \n",
    "print(f\"| **Precision (Model)**| {Precision_Corrected:.2%} |\")\n",
    "print(f\"| **Recall (Model)** | {Recall_Corrected:.2%} |\")\n",
    "print(f\"| **False Positives (FP)** | {FP} |\")\n",
    "print(f\"| **False Negatives (Pure Miss)** | {FN_pure} |\")\n",
    "print(f\"| **False Negatives (Suspect Data)** | {FN_suspect} |\")\n",
    "\n",
    "print(\"\\n| Confusion Matrix |\")\n",
    "# Display Confusion Matrix based on the newly calculated counts\n",
    "confusion_matrix = pd.DataFrame({\n",
    "    'LIVE': [TP, FP],\n",
    "    'NOT LIVE': [FN_pure, TN_clean],\n",
    "    'TIME SUSPECT': [FN_suspect, TN_suspect]\n",
    "}, index=['LIVE', 'NOT LIVE'])\n",
    "confusion_matrix.columns.name = 'Model Classification'\n",
    "confusion_matrix.index.name = 'Ground Truth'\n",
    "print(confusion_matrix.to_markdown())\n",
    "\n",
    "\n",
    "print(\"\\n| Examples of Incorrect Classification |\")\n",
    "# Filter for actual incorrects (FP + FN_pure + FN_suspect)\n",
    "incorrect_examples = df[(df['Ground Truth'] == 'LIVE') & (df['Model Classification'] != 'LIVE') | \n",
    "                        (df['Ground Truth'] == 'NOT LIVE') & (df['Model Classification'] == 'LIVE')].head(5)\n",
    "\n",
    "print(incorrect_examples[['Program Title', 'Start Datetime UTC', 'Duration_td', 'Ground Truth', 'Model Classification']].to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b75e3b9a-26a4-4629-874e-81d99e4d5478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DataFrame loaded successfully from Excel.\n",
      "\n",
      "Found 642 conflicting program entries across 97 unique event times.\n",
      "Generated program_outlier_treemap.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from datetime import datetime, time\n",
    "import plotly.express as px \n",
    "\n",
    "# --- 0. Data Loading ---\n",
    "# NOTE: Replace this section with your actual file loading code if running locally.\n",
    "try:\n",
    "    df = pd.read_excel(\n",
    "        \"data/WF 3 F1-R12 - Great Britain.xlsx\",\n",
    "        sheet_name=\"Worksheet\",\n",
    "        header=5 \n",
    "    )\n",
    "    print(\"âœ… DataFrame loaded successfully from Excel.\")\n",
    "except FileNotFoundError:\n",
    "    # Dummy data adapted for demonstration, ensuring conflicting entries exist\n",
    "    df = pd.DataFrame({\n",
    "        'Program Title': ['P1 Live', 'P1 Live', 'P1 Highlights', 'P1 Delayed', 'Race Live', 'Race Pre-Show', 'Race Replay', 'News'],\n",
    "        'Date (UTC/GMT)': pd.to_datetime(['2025-07-04', '2025-07-04', '2025-07-04', '2025-07-04', '2025-07-06', '2025-07-06', '2025-07-06', '2025-07-06']),\n",
    "        'Start (UTC)': [time(11, 30, 0), time(11, 30, 0), time(14, 0, 0), time(14, 0, 0), time(14, 0, 0), time(14, 0, 0), time(20, 0, 0), time(20, 0, 0)],\n",
    "        'Duration': ['01:30:00', '01:30:00', '00:45:00', '01:30:00', '02:00:00', '01:00:00', '02:00:00', '00:30:00'],\n",
    "        'Type of program': ['Live', 'Highlights', 'Highlights', 'Repeat', 'Live', 'Pre-Show', 'Repeat', 'News'], # Deliberately conflicting on 11:30 and 14:00/20:00\n",
    "        'Market': ['GB', 'FR', 'GB', 'DE', 'FR', 'DE', 'GB', 'FR'],\n",
    "        'Channel ID': [101.0, 102.0, 101.0, 101.0, 102.0, 101.0, 102.0, 101.0]\n",
    "    })\n",
    "    \n",
    "if df.empty:\n",
    "    print(\"Cannot proceed with an empty DataFrame.\")\n",
    "    exit()\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 1. Data Preparation (UTC Times and Harmonization)\n",
    "\n",
    "def extract_time_string(time_value):\n",
    "    if pd.isna(time_value): return '00:00:00'\n",
    "    if isinstance(time_value, time): return time_value.strftime('%H:%M:%S')\n",
    "    if isinstance(time_value, datetime): return time_value.time().strftime('%H:%M:%S')\n",
    "    try: return pd.to_datetime(str(time_value)).time().strftime('%H:%M:%S')\n",
    "    except: return '00:00:00'\n",
    "\n",
    "def harmonize_ground_truth(category):\n",
    "    category = str(category).strip().lower()\n",
    "    if category in ['live', 'live broadcast', 'race live', 'quali live']:\n",
    "        return 'LIVE'\n",
    "    elif category in ['repeat', 're-run', 'rerun', 'recap']:\n",
    "        return 'Repeat'\n",
    "    # Group ALL support/filler types into the general Highlights/Support category\n",
    "    elif category in ['highlights', 'short segment', 'review', 'news', 'pre-show', 'post-show', 'magazine', 'support', 'other', 'f1 news', 'magazine & support']:\n",
    "        return 'Support/Highlights'\n",
    "    else:\n",
    "        return 'Other/Original Label' \n",
    "\n",
    "# Create the key columns\n",
    "df['Date (UTC/GMT)'] = pd.to_datetime(df['Date (UTC/GMT)'], errors='coerce')\n",
    "df['Clean_Time_UTC_Str'] = df['Start (UTC)'].apply(extract_time_string)\n",
    "df['Start Datetime UTC'] = pd.to_datetime(df['Date (UTC/GMT)'].dt.strftime('%Y-%m-%d') + ' ' + df['Clean_Time_UTC_Str'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "df['Ground Truth'] = df['Type of program'].apply(harmonize_ground_truth)\n",
    "\n",
    "# Drop rows where the UTC time could not be calculated (critical for grouping)\n",
    "df_clean = df.dropna(subset=['Start Datetime UTC', 'Ground Truth']).copy()\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 2. Identify Conflicting Outlier Groups\n",
    "\n",
    "# Group by the unique event time (UTC) and count the number of unique program types\n",
    "conflict_summary = df_clean.groupby('Start Datetime UTC')['Ground Truth'].nunique().reset_index(name='Unique Types Count')\n",
    "\n",
    "# Identify events where more than one program type was recorded across markets\n",
    "conflicting_events = conflict_summary[conflict_summary['Unique Types Count'] > 1]\n",
    "\n",
    "# Merge to filter the original data down to only the conflicting rows\n",
    "df_outliers = pd.merge(\n",
    "    df_clean,\n",
    "    conflicting_events['Start Datetime UTC'],\n",
    "    on='Start Datetime UTC',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Format the Start Datetime UTC for better plotting labels\n",
    "df_outliers['Event Time Label'] = df_outliers['Start Datetime UTC'].dt.strftime('%Y-%m-%d %H:%M UTC')\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "## 3. Plot the Outliers (Treemap)\n",
    "\n",
    "if df_outliers.empty:\n",
    "    print(\"\\nNo conflicting outlier groups found based on unique Ground Truth for the same UTC start time.\")\n",
    "else:\n",
    "    print(f\"\\nFound {len(df_outliers)} conflicting program entries across {conflicting_events['Start Datetime UTC'].nunique()} unique event times.\")\n",
    "    \n",
    "    # Treemap visualization\n",
    "    fig = px.treemap(\n",
    "        df_outliers,\n",
    "        path=['Event Time Label', 'Market', 'Ground Truth'],\n",
    "        color='Ground Truth',\n",
    "        title='Distribution of Conflicting Program Types (Outliers)',\n",
    "        color_discrete_map={'LIVE': 'green', 'Repeat': 'blue', 'Support/Highlights': 'orange', 'Other/Original Label': 'lightgrey'},\n",
    "        hover_data=['Program Title', 'Channel ID']\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(margin = dict(t=50, l=25, r=25, b=25))\n",
    "    fig.write_json(\"program_outlier_treemap.json\")\n",
    "    print(\"Generated program_outlier_treemap.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f591d168-b868-4ebf-9007-0b1e7a93ed89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
