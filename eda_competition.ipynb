{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01340fe4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Region     Market  Market ID Broadcaster  \\\n",
      "0  Central and South America  Argentina       74.0        ESPN   \n",
      "1  Central and South America  Argentina       74.0    Mediapro   \n",
      "2  Central and South America  Argentina       74.0    Mediapro   \n",
      "3  Central and South America  Argentina       74.0    Mediapro   \n",
      "4  Central and South America  Argentina       74.0    Mediapro   \n",
      "\n",
      "         TV-Channel  Channel ID Pay/Free TV Date (UTC/GMT)       Date  \\\n",
      "0        ESPN 2 ARG      1210.0         NaN     2025-07-04 2025-07-03   \n",
      "1  Fox Sports (ARG)      2732.0         NaN     2025-07-04 2025-07-04   \n",
      "2  Fox Sports (ARG)      2732.0         NaN     2025-07-04 2025-07-04   \n",
      "3  Fox Sports (ARG)      2732.0         NaN     2025-07-05 2025-07-04   \n",
      "4  Fox Sports (ARG)      2732.0         NaN     2025-07-05 2025-07-04   \n",
      "\n",
      "                   Day  ... Spot price in Euro [1 sec.] Fixture analysis  \\\n",
      "0  2025-07-03 00:00:00  ...                         NaN              NaN   \n",
      "1  2025-07-04 00:00:00  ...                         NaN              NaN   \n",
      "2  2025-07-04 00:00:00  ...                         NaN              NaN   \n",
      "3  2025-07-04 00:00:00  ...                         NaN              NaN   \n",
      "4  2025-07-04 00:00:00  ...                         NaN              NaN   \n",
      "\n",
      "  Brandbase upload Source BT Start BT Duration Unnamed: 43 Unnamed: 44  \\\n",
      "0              NaN  IBOPE      NaN         NaN         NaN         NaN   \n",
      "1              NaN  IBOPE      NaN         NaN         NaN         NaN   \n",
      "2              NaN  IBOPE      NaN         NaN         NaN         NaN   \n",
      "3              NaN  IBOPE      NaN         NaN         NaN         NaN   \n",
      "4              NaN  IBOPE      NaN         NaN         NaN         NaN   \n",
      "\n",
      "  Unnamed: 45 Unnamed: 46  \n",
      "0         NaN         NaN  \n",
      "1         NaN         NaN  \n",
      "2         NaN         NaN  \n",
      "3         NaN         NaN  \n",
      "4         NaN         NaN  \n",
      "\n",
      "[5 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\n",
    "    \"data/WF 3 F1-R12 - Great Britain.xlsx\",\n",
    "    sheet_name=\"Worksheet\",  # Specify the tab name\n",
    "    header=5 # Specify the 4th row as the header\n",
    ")\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3d7a171",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BHRAJG2501\\Desktop\\Formula_1\\.venv\\Lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from typing import List ,Dict,Any\n",
    "from openpyxl.styles import PatternFill\n",
    "from pandas.api.types import is_object_dtype, is_categorical_dtype, CategoricalDtype \n",
    "from fuzzywuzzy import fuzz\n",
    "from datetime import datetime\n",
    "\n",
    "def _create_session_schedule(self):\n",
    "    \"\"\"Creates the definitive schedule DataFrame for mapping.\"\"\"\n",
    "    data = {\n",
    "        'Session': [\n",
    "            'Practice 1', 'Practice 2', 'Practice 3', \n",
    "            'Qualifying', 'GRAND PRIX (52 LAPS OR 120 MINS)'\n",
    "        ],\n",
    "        'Date': [\n",
    "            '4-Jul-2025', '4-Jul-2025', '5-Jul-2025', \n",
    "            '5-Jul-2025', '6-Jul-2025'\n",
    "        ],\n",
    "        'Start Time': [\n",
    "            '11:30:00', '15:00:00', '10:30:00', \n",
    "            '14:00:00', '14:00:00'\n",
    "        ]\n",
    "    }\n",
    "    df_schedule = pd.DataFrame(data)\n",
    "\n",
    "    # 1. Standardize the Session names to your target categories\n",
    "    df_schedule['Target_Competition'] = np.select(\n",
    "        [\n",
    "            df_schedule['Session'].str.contains('Practice'),\n",
    "            df_schedule['Session'] == 'Qualifying',\n",
    "            df_schedule['Session'].str.contains('GRAND PRIX')\n",
    "        ],\n",
    "        ['Training', 'Qualifying', 'Race'],\n",
    "        default='Support' # Default should theoretically not be hit here\n",
    "    )\n",
    "\n",
    "    # 2. Create the precise key for joining (Date + Time)\n",
    "    # NOTE: This assumes BSR's Start (UTC) is a string representation of time\n",
    "    df_schedule['Date_Key'] = pd.to_datetime(df_schedule['Date']).dt.date\n",
    "    df_schedule['Start_Key'] = df_schedule['Start Time'].str.strip()\n",
    "\n",
    "    return df_schedule[['Target_Competition', 'Date_Key', 'Start_Key']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0db8cd12-5483-4539-a335-9e9f16479dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _impute_competition_sessions(self) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Imputes blank values in the 'Competition' column by matching 'Date' and 'Start Time' \n",
    "    against the known GP schedule.\n",
    "    \"\"\"\n",
    "    initial_blanks = self.df['Competition'].isna().sum()\n",
    "    \n",
    "    # Check for required BSR columns\n",
    "    required_cols = ['Date (UTC/GMT)', 'Start (UTC)', 'Competition']\n",
    "    if not all(col in self.df.columns for col in required_cols):\n",
    "         return {\n",
    "            \"check_key\": \"impute_competition\",\n",
    "            \"status\": \"Skipped\",\n",
    "            \"action\": \"Competition Imputation\",\n",
    "            \"description\": f\"Skipped: Missing required BSR columns {required_cols}.\",\n",
    "            \"details\": {\"rows_imputed\": 0}\n",
    "        }\n",
    "    \n",
    "    # Get the schedule reference table\n",
    "    df_schedule = self._create_session_schedule()\n",
    "    \n",
    "    # --- Prepare BSR for Join ---\n",
    "    df_temp = self.df.copy()\n",
    "    \n",
    "    # 1. Convert BSR Date column to match schedule key format (date object)\n",
    "    df_temp['Date_Key'] = pd.to_datetime(df_temp['Date (UTC/GMT)']).dt.date\n",
    "    \n",
    "    # 2. Use BSR Start Time column as the time key (assuming it was standardized earlier)\n",
    "    # NOTE: Assuming Start (UTC) was converted to string/object earlier\n",
    "    df_temp['Start_Key'] = df_temp['Start (UTC)'].astype(str).str.strip() \n",
    "\n",
    "    # --- Perform Left Merge ---\n",
    "    # Merge BSR with Schedule on (Date, Start Time) to pull in 'Target_Competition'\n",
    "    df_temp = df_temp.merge(\n",
    "        df_schedule, \n",
    "        on=['Date_Key', 'Start_Key'], \n",
    "        how='left', \n",
    "        suffixes=('', '_Map')\n",
    "    )\n",
    "    \n",
    "    # --- Imputation Logic ---\n",
    "    \n",
    "    # Identify rows that are currently blank in the Competition column\n",
    "    blank_mask = self.df['Competition'].isna() | (self.df['Competition'].astype(str).str.strip() == '')\n",
    "\n",
    "    # Identify rows where the BSR matched a session in the schedule\n",
    "    matched_mask = blank_mask & df_temp['Target_Competition'].notna()\n",
    "    \n",
    "    # 1. Fill matched blanks with the correct session name\n",
    "    self.df.loc[matched_mask, 'Competition'] = df_temp.loc[matched_mask, 'Target_Competition']\n",
    "    \n",
    "    # 2. Fill the remaining unmatched blanks with 'Support'\n",
    "    remaining_blanks_mask = self.df['Competition'].isna() | (self.df['Competition'].astype(str).str.strip() == '')\n",
    "    self.df.loc[remaining_blanks_mask, 'Competition'] = 'Support'\n",
    "    \n",
    "    # --- Clean Up and Report ---\n",
    "    rows_imputed = matched_mask.sum()\n",
    "    rows_defaulted_to_support = remaining_blanks_mask.sum() - rows_imputed # Rough count of those not matched\n",
    "    \n",
    "    return {\n",
    "        \"check_key\": \"impute_competition\",\n",
    "        \"status\": \"Completed\",\n",
    "        \"action\": \"Competition Imputation\",\n",
    "        \"description\": f\"Imputed blank 'Competition' values: {rows_imputed} rows mapped to sessions, {rows_defaulted_to_support} defaulted to 'Support'.\",\n",
    "        \"details\": {\n",
    "            \"rows_imputed\": int(rows_imputed),\n",
    "            \"rows_defaulted_to_support\": int(rows_defaulted_to_support),\n",
    "            \"initial_blanks\": int(initial_blanks)\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30ef9edc-44bc-42e3-8030-c97448bee2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Competition Imputation Results ---\n",
      "Total Rows Mapped to Sessions (Training/Qualifying/Race): 139\n",
      "Total Rows Defaulted to 'Support': 2855\n",
      "\n",
      "DataFrame head showing original and imputed values:\n",
      "  Date (UTC/GMT) Start (UTC) Competition Imputed_Competition  \\\n",
      "0     2025-07-04    01:00:00     Support             Support   \n",
      "1     2025-07-04    19:00:03    Training             Support   \n",
      "2     2025-07-04    20:09:29    Training             Support   \n",
      "3     2025-07-05    00:01:16    Training             Support   \n",
      "4     2025-07-05    01:11:25    Training             Support   \n",
      "5     2025-07-05    18:01:27    Training             Support   \n",
      "6     2025-07-05    19:12:10  Qualifying             Support   \n",
      "7     2025-07-05    22:30:00    Training             Support   \n",
      "8     2025-07-05    23:40:39  Qualifying             Support   \n",
      "9     2025-07-06    10:30:09    Training             Support   \n",
      "\n",
      "                                       Program Title  \n",
      "0  El Show de la F1        -O El Show de la F1   ...  \n",
      "1                             FORMULA 1 PRACTICAS(R)  \n",
      "2                            FORMULA 1 PRACTICAS(R2)  \n",
      "3                            FORMULA 1 PRACTICAS(R3)  \n",
      "4                            FORMULA 1 PRACTICAS(R4)  \n",
      "5                             FORMULA 1 PRACTICAS(R)  \n",
      "6                           FORMULA UNO CLASIFICA(R)  \n",
      "7                            FORMULA 1 PRACTICAS(R2)  \n",
      "8                          FORMULA UNO CLASIFICA(R2)  \n",
      "9                             FORMULA 1 PRACTICAS(R)  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BHRAJG2501\\AppData\\Local\\Temp\\1\\ipykernel_27888\\418043032.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Race' 'Training' 'Training' 'Training' 'Qualifying' 'Race' 'Training'\n",
      " 'Training' 'Training' 'Qualifying' 'Race' 'Qualifying' 'Training'\n",
      " 'Training' 'Training' 'Qualifying' 'Race' 'Training' 'Training'\n",
      " 'Training' 'Training' 'Qualifying' 'Race' 'Race' 'Qualifying' 'Training'\n",
      " 'Training' 'Training' 'Qualifying' 'Race' 'Training' 'Training'\n",
      " 'Training' 'Qualifying' 'Training' 'Training' 'Training' 'Qualifying'\n",
      " 'Race' 'Training' 'Training' 'Training' 'Qualifying' 'Race' 'Training'\n",
      " 'Training' 'Training' 'Qualifying' 'Race' 'Training' 'Training'\n",
      " 'Training' 'Qualifying' 'Race' 'Training' 'Training' 'Training'\n",
      " 'Qualifying' 'Race' 'Training' 'Training' 'Training' 'Qualifying' 'Race'\n",
      " 'Race' 'Training' 'Training' 'Training' 'Qualifying' 'Race' 'Training'\n",
      " 'Training' 'Training' 'Qualifying' 'Race' 'Training' 'Training'\n",
      " 'Training' 'Qualifying' 'Race' 'Qualifying' 'Race' 'Qualifying'\n",
      " 'Training' 'Training' 'Training' 'Qualifying' 'Race' 'Training'\n",
      " 'Training' 'Qualifying' 'Race' 'Training' 'Training' 'Training'\n",
      " 'Qualifying' 'Race' 'Training' 'Training' 'Training' 'Qualifying' 'Race'\n",
      " 'Race' 'Training' 'Training' 'Training' 'Qualifying' 'Race' 'Training'\n",
      " 'Race' 'Qualifying' 'Race' 'Training' 'Training' 'Training' 'Qualifying'\n",
      " 'Race' 'Training' 'Training' 'Training' 'Qualifying' 'Race' 'Training'\n",
      " 'Training' 'Training' 'Qualifying' 'Race' 'Training' 'Training'\n",
      " 'Training' 'Qualifying' 'Race' 'Training' 'Training' 'Training'\n",
      " 'Qualifying' 'Training' 'Qualifying' 'Qualifying']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[matched_mask, 'Imputed_Competition'] = df.loc[matched_mask, 'Target_Competition']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Define the Schedule Function ---\n",
    "def _create_session_schedule():\n",
    "    \"\"\"Creates the definitive schedule DataFrame for mapping.\"\"\"\n",
    "    data = {\n",
    "        'Session': [\n",
    "            'Practice 1', 'Practice 2', 'Practice 3', \n",
    "            'Qualifying', 'GRAND PRIX (52 LAPS OR 120 MINS)'\n",
    "        ],\n",
    "        'Date': [\n",
    "            '4-Jul-2025', '4-Jul-2025', '5-Jul-2025', \n",
    "            '5-Jul-2025', '6-Jul-2025'\n",
    "        ],\n",
    "        'Start Time': [\n",
    "            '11:30:00', '15:00:00', '10:30:00', \n",
    "            '14:00:00', '14:00:00'\n",
    "        ]\n",
    "    }\n",
    "    df_schedule = pd.DataFrame(data)\n",
    "\n",
    "    # Standardize Session names to your target categories\n",
    "    df_schedule['Target_Competition'] = np.select(\n",
    "        [\n",
    "            df_schedule['Session'].str.contains('Practice'),\n",
    "            df_schedule['Session'] == 'Qualifying',\n",
    "            df_schedule['Session'].str.contains('GRAND PRIX')\n",
    "        ],\n",
    "        ['Training', 'Qualifying', 'Race'],\n",
    "        default='Support' # Default should not be hit if input is clean\n",
    "    )\n",
    "\n",
    "    # Create the precise key for joining: Date (as date object) + Time (as string)\n",
    "    df_schedule['Date_Key'] = pd.to_datetime(df_schedule['Date']).dt.date\n",
    "    df_schedule['Start_Key'] = df_schedule['Start Time'].str.strip()\n",
    "\n",
    "    return df_schedule[['Target_Competition', 'Date_Key', 'Start_Key']]\n",
    "\n",
    "\n",
    "# --- 2. Load and Prepare Data ---\n",
    "try:\n",
    "    df = pd.read_excel(\n",
    "        \"data/WF 3 F1-R12 - Great Britain.xlsx\",\n",
    "        sheet_name=\"Worksheet\",\n",
    "        header=5\n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    print(\"Execution halted: File not found.\")\n",
    "    df = pd.DataFrame() # Create an empty DF to avoid further errors\n",
    "\n",
    "\n",
    "if not df.empty and 'Competition' in df.columns:\n",
    "    \n",
    "    # Preparation Steps for BSR (Needed for merging)\n",
    "    df['Date_Key'] = pd.to_datetime(df['Date (UTC/GMT)']).dt.date\n",
    "    df['Start_Key'] = df['Start (UTC)'].astype(str).str.strip() \n",
    "\n",
    "    # Get the schedule reference table\n",
    "    df_schedule = _create_session_schedule()\n",
    "\n",
    "    # --- 3. Perform Left Merge (Mapping) ---\n",
    "    # Merge BSR with Schedule on (Date, Start Time) to pull in 'Target_Competition'\n",
    "    df = df.merge(\n",
    "        df_schedule, \n",
    "        on=['Date_Key', 'Start_Key'], \n",
    "        how='left', \n",
    "        suffixes=('', '_Map')\n",
    "    )\n",
    "\n",
    "    # --- 4. Imputation Logic: Create New Column ---\n",
    "\n",
    "    # Initialize the new column with a placeholder value indicating no match was found\n",
    "    df['Imputed_Competition'] = np.nan \n",
    "    \n",
    "    # 1. Fill the new column with the successfully mapped session name (Training, Qualifying, Race)\n",
    "    # This targets ALL rows, regardless of whether the original Competition column was blank.\n",
    "    matched_mask = df['Target_Competition'].notna()\n",
    "    df.loc[matched_mask, 'Imputed_Competition'] = df.loc[matched_mask, 'Target_Competition']\n",
    "    rows_imputed = matched_mask.sum() # Total rows that matched the schedule\n",
    "\n",
    "    # 2. Default the remaining NaNs in the new column to 'Support'\n",
    "    rows_defaulted_to_support = df['Imputed_Competition'].isna().sum()\n",
    "    df['Imputed_Competition'] = df['Imputed_Competition'].fillna('Support')\n",
    "\n",
    "    # --- Clean Up and Display Results ---\n",
    "    df = df.drop(columns=['Date_Key', 'Start_Key', 'Target_Competition'])\n",
    "\n",
    "    # Calculate initial and final states for comparison\n",
    "    initial_blanks = df['Competition'].isna().sum() \n",
    "    \n",
    "    print(f\"\\n--- Competition Imputation Results ---\")\n",
    "    print(f\"Total Rows Mapped to Sessions (Training/Qualifying/Race): {rows_imputed}\")\n",
    "    print(f\"Total Rows Defaulted to 'Support': {rows_defaulted_to_support}\")\n",
    "    \n",
    "    print(\"\\nDataFrame head showing original and imputed values:\")\n",
    "    # Display the original Competition column alongside the new imputed one\n",
    "    print(df[['Date (UTC/GMT)', 'Start (UTC)', 'Competition', 'Imputed_Competition', 'Program Title']].head(10))\n",
    "\n",
    "else:\n",
    "    print(\"DataFrame is empty or missing the 'Competition' column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "818a3b09-9b55-4bd9-bd8e-03b70929c9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Program Type Imputation Results (Logical) ---\n",
      "Total Rows Imputed (Live/Repeat/Highlights): 2015\n",
      "Total Rows Defaulted to 'Magazine & Support': 979\n",
      "\n",
      "DataFrame head showing Imputed Program Type:\n",
      "  Date (UTC/GMT) Start (UTC)  \\\n",
      "0     2025-07-04    01:00:00   \n",
      "1     2025-07-04    19:00:03   \n",
      "2     2025-07-04    20:09:29   \n",
      "3     2025-07-05    00:01:16   \n",
      "4     2025-07-05    01:11:25   \n",
      "5     2025-07-05    18:01:27   \n",
      "6     2025-07-05    19:12:10   \n",
      "7     2025-07-05    22:30:00   \n",
      "8     2025-07-05    23:40:39   \n",
      "9     2025-07-06    10:30:09   \n",
      "\n",
      "                                       Program Title     Type of program  \\\n",
      "0  El Show de la F1        -O El Show de la F1   ...  Magazine & Support   \n",
      "1                             FORMULA 1 PRACTICAS(R)              Repeat   \n",
      "2                            FORMULA 1 PRACTICAS(R2)              Repeat   \n",
      "3                            FORMULA 1 PRACTICAS(R3)              Repeat   \n",
      "4                            FORMULA 1 PRACTICAS(R4)              Repeat   \n",
      "5                             FORMULA 1 PRACTICAS(R)              Repeat   \n",
      "6                           FORMULA UNO CLASIFICA(R)              Repeat   \n",
      "7                            FORMULA 1 PRACTICAS(R2)              Repeat   \n",
      "8                          FORMULA UNO CLASIFICA(R2)              Repeat   \n",
      "9                             FORMULA 1 PRACTICAS(R)              Repeat   \n",
      "\n",
      "  Imputed_Program_Type  \n",
      "0   Magazine & Support  \n",
      "1   Magazine & Support  \n",
      "2   Magazine & Support  \n",
      "3           Highlights  \n",
      "4           Highlights  \n",
      "5           Highlights  \n",
      "6           Highlights  \n",
      "7           Highlights  \n",
      "8           Highlights  \n",
      "9           Highlights  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "# Define the schedule function outside the main logic block\n",
    "def _get_f1_live_schedule():\n",
    "    \"\"\"Creates a standardized DataFrame of official F1 live session windows (UTC).\"\"\"\n",
    "    data = {\n",
    "        'Session': ['Practice 1', 'Practice 2', 'Practice 3', 'Qualifying', 'GRAND PRIX'],\n",
    "        'Date': ['4-Jul-2025', '4-Jul-2025', '5-Jul-2025', '5-Jul-2025', '6-Jul-2025'],\n",
    "        'Start Time': ['11:30:00', '15:00:00', '10:30:00', '14:00:00', '14:00:00'],\n",
    "        'End Time': ['12:30:00', '16:00:00', '11:30:00', '15:00:00', '16:00:00']\n",
    "    }\n",
    "    df_schedule = pd.DataFrame(data)\n",
    "\n",
    "    df_schedule['Live_Start_UTC'] = pd.to_datetime(df_schedule['Date'] + ' ' + df_schedule['Start Time'])\n",
    "    df_schedule['Live_End_UTC'] = pd.to_datetime(df_schedule['Date'] + ' ' + df_schedule['End Time'])\n",
    "\n",
    "    return df_schedule\n",
    "\n",
    "def get_time_string(series):\n",
    "    dt_series = pd.to_datetime(series, errors='coerce', format='mixed')\n",
    "    time_series = dt_series.dt.strftime('%H:%M:%S').fillna('00:00:00')\n",
    "    return time_series\n",
    "\n",
    "# --- 2. Load and Prepare Data (Mocking a BSR Load) ---\n",
    "try:\n",
    "    df = pd.read_excel(\n",
    "        \"data/WF 3 F1-R12 - Great Britain.xlsx\",\n",
    "        sheet_name=\"Worksheet\",\n",
    "        header=5\n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    print(\"Execution halted: File not found.\")\n",
    "    df = pd.DataFrame() \n",
    "\n",
    "if not df.empty:\n",
    "    NEW_COL = 'Imputed_Program_Type'\n",
    "    \n",
    "    # 1. Clean and Prepare Time/Date Columns (Essential for logic)\n",
    "    df['Program Title'] = df['Program Title'].astype(str).str.strip()\n",
    "    df['Start_Time_Clean'] = get_time_string(df['Start (UTC)'])\n",
    "    df['End_Time_Clean'] = get_time_string(df['End (UTC)'])\n",
    "    \n",
    "    try:\n",
    "        # Create robust datetime objects for comparison\n",
    "        date_dt = pd.to_datetime(df['Date (UTC/GMT)'], errors='coerce', format='mixed').dt.strftime('%Y-%m-%d')\n",
    "        date_dt_clean = date_dt.fillna('1970-01-01') \n",
    "\n",
    "        bsr_dates = pd.to_datetime(date_dt_clean + ' ' + df['Start_Time_Clean'], errors='coerce')\n",
    "        bsr_ends = pd.to_datetime(date_dt_clean + ' ' + df['End_Time_Clean'], errors='coerce')\n",
    "        \n",
    "        # Calculate BSR Duration in minutes\n",
    "        bsr_duration_minutes = (bsr_ends - bsr_dates) / timedelta(minutes=1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to parse BSR Date/Time columns: {e}\")\n",
    "        df = pd.DataFrame() \n",
    "\n",
    "if not df.empty:\n",
    "    \n",
    "    # Initialize the new column with the default category\n",
    "    df[NEW_COL] = 'Magazine & Support'\n",
    "    rows_imputed = 0\n",
    "    \n",
    "    df_schedule = _get_f1_live_schedule()\n",
    "\n",
    "    # --- Logical Thresholds ---\n",
    "    LIVE_TIME_TOLERANCE_MIN = 5      # Must start within 5 minutes of official live start\n",
    "    LIVE_DURATION_TOLERANCE_PCT = 0.10 # Duration must be within 10% of official live duration\n",
    "    HIGHLIGHT_MAX_DURATION_MIN = 60  # Highlights/Magazines are typically 1 hour or less\n",
    "\n",
    "    # --- Primary Program Type Imputation ---\n",
    "    \n",
    "    for _, session in df_schedule.iterrows():\n",
    "        live_start = session['Live_Start_UTC']\n",
    "        live_end = session['Live_End_UTC']\n",
    "        live_duration = (live_end - live_start) / timedelta(minutes=1)\n",
    "        \n",
    "        # 1. Calculate time differences and duration windows\n",
    "        time_diff_abs = (bsr_dates - live_start).abs() / timedelta(minutes=1)\n",
    "        time_diff_actual = (bsr_dates - live_start) / timedelta(minutes=1)\n",
    "        \n",
    "        duration_min = live_duration * (1 - LIVE_DURATION_TOLERANCE_PCT)\n",
    "        duration_max = live_duration * (1 + LIVE_DURATION_TOLERANCE_PCT)\n",
    "        \n",
    "        is_long_duration = (bsr_duration_minutes >= duration_min)\n",
    "        is_short_duration = (bsr_duration_minutes <= HIGHLIGHT_MAX_DURATION_MIN)\n",
    "        \n",
    "        # --- SEGREGATION MASKS (Hierarchical Logic) ---\n",
    "        \n",
    "        # MASK A: LIVE (Highest Confidence)\n",
    "        # Starts very close to official time (before or slightly after) AND matches duration.\n",
    "        LIVE_MATCH_MASK = is_long_duration & (time_diff_abs <= LIVE_TIME_TOLERANCE_MIN)\n",
    "\n",
    "        # MASK B: REPEAT (Full session rebroadcast)\n",
    "        # Matches duration but starts SIGNIFICANTLY later (e.g., more than 6 hours later, or next day)\n",
    "        # This catches full-session reruns that are not live.\n",
    "        REPEAT_MATCH_MASK = is_long_duration & (time_diff_actual > (6 * 60)) \n",
    "\n",
    "        # MASK C: HIGHLIGHTS\n",
    "        # Short duration AND not a repeat AND occurs after the official session end.\n",
    "        # It's an approximation, but captures post-session short-form content.\n",
    "        HIGHLIGHTS_MATCH_MASK = is_short_duration & \\\n",
    "                                (bsr_dates > live_end) & \\\n",
    "                                (time_diff_actual > LIVE_TIME_TOLERANCE_MIN)\n",
    "        \n",
    "        # --- Apply Flags (Hierarchically) ---\n",
    "        \n",
    "        # Only target rows that still hold the default 'Magazine & Support' flag\n",
    "\n",
    "        # 1. Apply LIVE Flag\n",
    "        live_final_mask = LIVE_MATCH_MASK & (df[NEW_COL] == 'Magazine & Support')\n",
    "        df.loc[live_final_mask, NEW_COL] = 'Live'\n",
    "        rows_imputed += live_final_mask.sum()\n",
    "        \n",
    "        # 2. Apply REPEAT Flag (Only to rows NOT already marked Live)\n",
    "        repeat_final_mask = REPEAT_MATCH_MASK & (df[NEW_COL] == 'Magazine & Support')\n",
    "        df.loc[repeat_final_mask, NEW_COL] = 'Repeat'\n",
    "        rows_imputed += repeat_final_mask.sum()\n",
    "        \n",
    "        # 3. Apply HIGHLIGHTS Flag (Only to remaining rows)\n",
    "        highlights_final_mask = HIGHLIGHTS_MATCH_MASK & (df[NEW_COL] == 'Magazine & Support')\n",
    "        df.loc[highlights_final_mask, NEW_COL] = 'Highlights'\n",
    "        rows_imputed += highlights_final_mask.sum()\n",
    "\n",
    "\n",
    "    # --- Final Cleanup and Display Results ---\n",
    "    \n",
    "    rows_defaulted_to_support = (df[NEW_COL] == 'Magazine & Support').sum()\n",
    "    \n",
    "    print(f\"\\n--- Program Type Imputation Results (Logical) ---\")\n",
    "    print(f\"Total Rows Imputed (Live/Repeat/Highlights): {rows_imputed}\")\n",
    "    print(f\"Total Rows Defaulted to 'Magazine & Support': {rows_defaulted_to_support}\")\n",
    "    \n",
    "    print(\"\\nDataFrame head showing Imputed Program Type:\")\n",
    "    print(df[['Date (UTC/GMT)', 'Start (UTC)', 'Program Title', 'Type of program', NEW_COL]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383d1bc7-92ff-4523-a7f7-c9a7e557ca95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51563c81-c3ca-40ab-be95-0e2134cdffbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
